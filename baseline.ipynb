{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to raed12\\CartPole_baseline3_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.5     |\n",
      "|    ep_rew_mean     | 21.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 196      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.1         |\n",
      "|    ep_rew_mean          | 28.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 167          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095014665 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | -0.00285     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.2          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.3        |\n",
      "|    ep_rew_mean          | 32.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 174         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010322653 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.2        |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 182         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008146068 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 50.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.5        |\n",
      "|    ep_rew_mean          | 59.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 186         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008340266 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 72.8         |\n",
      "|    ep_rew_mean          | 72.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072530014 |\n",
      "|    clip_fraction        | 0.0655       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.6         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 59.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 90.6         |\n",
      "|    ep_rew_mean          | 90.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 187          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072001833 |\n",
      "|    clip_fraction        | 0.0753       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.9         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 57.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | 110         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 188         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010107737 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 189         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003952396 |\n",
      "|    clip_fraction        | 0.0332      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.563      |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 68.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 146         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 191         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006942792 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 163          |\n",
      "|    ep_rew_mean          | 163          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 191          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059159803 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    value_loss           | 10.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 183         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 193         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007695198 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.6         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 201          |\n",
      "|    ep_rew_mean          | 201          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 194          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019010165 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.3         |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 218        |\n",
      "|    ep_rew_mean          | 218        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 194        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00544956 |\n",
      "|    clip_fraction        | 0.0473     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.532     |\n",
      "|    explained_variance   | 0.65       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.232      |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00469   |\n",
      "|    value_loss           | 2.84       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 234          |\n",
      "|    ep_rew_mean          | 234          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054199114 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    value_loss           | 2.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 251          |\n",
      "|    ep_rew_mean          | 251          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063617104 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.134        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0816       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.07         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 268          |\n",
      "|    ep_rew_mean          | 268          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 177          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036784825 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | -0.0384      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0469       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000275    |\n",
      "|    value_loss           | 0.702        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 286          |\n",
      "|    ep_rew_mean          | 286          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020476987 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0776       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0189       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.000951    |\n",
      "|    value_loss           | 0.427        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 304          |\n",
      "|    ep_rew_mean          | 304          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031772736 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | -0.0183      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0137       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -6.97e-07    |\n",
      "|    value_loss           | 0.258        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m TIMESTEPS \u001b[39m=\u001b[39m \u001b[39m1_000_000\u001b[39m\n\u001b[0;32m     15\u001b[0m iters \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mTIMESTEPS, reset_num_timesteps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,tb_log_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCartPole_baseline3\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:169\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     obs_tensor \u001b[39m=\u001b[39m obs_as_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 169\u001b[0m     actions, values, log_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy(obs_tensor)\n\u001b[0;32m    170\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    172\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:628\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    626\u001b[0m distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n\u001b[0;32m    627\u001b[0m actions \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[1;32m--> 628\u001b[0m log_prob \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39;49mlog_prob(actions)\n\u001b[0;32m    629\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m actions, values, log_prob\n",
      "File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\stable_baselines3\\common\\distributions.py:292\u001b[0m, in \u001b[0;36mCategoricalDistribution.log_prob\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, actions: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m--> 292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistribution\u001b[39m.\u001b[39;49mlog_prob(actions)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\distributions\\categorical.py:124\u001b[0m, in \u001b[0;36mCategorical.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args:\n\u001b[0;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_sample(value)\n\u001b[1;32m--> 124\u001b[0m value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mlong()\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    125\u001b[0m value, log_pmf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbroadcast_tensors(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits)\n\u001b[0;32m    126\u001b[0m value \u001b[39m=\u001b[39m value[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "models_dir = \"raed12\"\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "model = PPO('MlpPolicy', 'CartPole-v1', verbose=1, tensorboard_log=models_dir)\n",
    "\n",
    "TIMESTEPS = 1_000_000\n",
    "iters = 0\n",
    "model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False,tb_log_name='CartPole_baseline3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
