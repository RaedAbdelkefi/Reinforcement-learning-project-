{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network(nn.Module):\n",
    "    def __init__(self,input_dims,output_dims):\n",
    "        super(neural_network,self).__init__()\n",
    "        self.layer1=nn.Linear(input_dims,64)\n",
    "        self.layer2=nn.Linear(64,64)\n",
    "        self.layer3=nn.Linear(64,output_dims)\n",
    "    def forward(self,state):\n",
    "        if isinstance(state,np.ndarray):\n",
    "            state=torch.tensor(state,dtype=torch.float)\n",
    "            \n",
    "        act1=F.relu(self.layer1(state))\n",
    "        act2=F.relu(self.layer2(act1))\n",
    "        output=self.layer3(act2)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.83772224, -0.5460965 ,  0.89465517], dtype=float32), {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1=gym.make('Pendulum-v1')\n",
    "# env1=gym.vector.SyncVectorEnv(env)\n",
    "env1.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "for i in range(4):\n",
    "    \n",
    "    L.append(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "array([1, 0, 0, 0]) (<class 'numpy.ndarray'>) invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_stata,reward,done,_,_\u001b[39m=\u001b[39menv\u001b[39m.\u001b[39;49mstep(np\u001b[39m.\u001b[39;49marray([\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m]))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:133\u001b[0m, in \u001b[0;36mCartPoleEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m--> 133\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mcontains(\n\u001b[0;32m    134\u001b[0m         action\n\u001b[0;32m    135\u001b[0m     ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00maction\u001b[39m!r}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(action)\u001b[39m}\u001b[39;00m\u001b[39m) invalid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mCall reset before using step method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     x, x_dot, theta, theta_dot \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n",
      "\u001b[1;31mAssertionError\u001b[0m: array([1, 0, 0, 0]) (<class 'numpy.ndarray'>) invalid"
     ]
    }
   ],
   "source": [
    "new_stata,reward,done,_,_=env.step(np.array([1,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=\n",
    "dist = MultivariateNormal(mean, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0739300e+37,  1.4293945e+37,  1.0251376e+36, -5.9085093e+36],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor=neural_network(4,4)\n",
    "actor(np.array([-2.6352916e+00, -2.2844338e+38,  2.9501456e-01, -2.7980816e+37],\n",
    "       dtype=float)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('layer1.weight',\n",
       "               tensor([[-0.4751, -0.4852,  0.1991, -0.3985],\n",
       "                       [ 0.0364, -0.1829, -0.4313,  0.0102],\n",
       "                       [-0.4279, -0.4596, -0.4668,  0.1448],\n",
       "                       [ 0.0063,  0.3088, -0.0284, -0.3186],\n",
       "                       [ 0.2166,  0.4812, -0.4225,  0.2312],\n",
       "                       [ 0.4791, -0.0249,  0.0465, -0.2635],\n",
       "                       [ 0.4325, -0.3278,  0.1359,  0.0443],\n",
       "                       [-0.0836, -0.3002, -0.4430, -0.0476],\n",
       "                       [ 0.3805,  0.0448, -0.2599,  0.2697],\n",
       "                       [-0.0776,  0.4100, -0.0113,  0.3646],\n",
       "                       [-0.3142, -0.3397, -0.2897, -0.1162],\n",
       "                       [-0.4083,  0.3879,  0.3437, -0.4438],\n",
       "                       [-0.4216, -0.1533, -0.0685, -0.2068],\n",
       "                       [-0.2390, -0.4049, -0.2300,  0.0419],\n",
       "                       [ 0.3623, -0.0320, -0.3449, -0.1044],\n",
       "                       [-0.4619,  0.3191,  0.4359, -0.0747],\n",
       "                       [-0.1528, -0.3937,  0.1209,  0.2750],\n",
       "                       [ 0.3441,  0.1043, -0.0661, -0.2692],\n",
       "                       [-0.0452,  0.0832,  0.4688,  0.2120],\n",
       "                       [ 0.4765,  0.4430,  0.2486, -0.3249],\n",
       "                       [-0.4608, -0.4469,  0.2502, -0.3429],\n",
       "                       [ 0.2946,  0.2089, -0.2682,  0.4990],\n",
       "                       [-0.2049,  0.4529,  0.3367,  0.1874],\n",
       "                       [-0.0593, -0.2401, -0.1659,  0.3452],\n",
       "                       [-0.3720,  0.1978,  0.2789, -0.0824],\n",
       "                       [ 0.3214,  0.2878,  0.4532,  0.0119],\n",
       "                       [ 0.1687, -0.4797, -0.2451,  0.1360],\n",
       "                       [-0.3917, -0.2323,  0.4986, -0.3767],\n",
       "                       [ 0.1496, -0.0164,  0.4494,  0.4103],\n",
       "                       [-0.3483,  0.1097, -0.1433, -0.1843],\n",
       "                       [ 0.3705, -0.0533, -0.2259, -0.1897],\n",
       "                       [ 0.4776, -0.2826,  0.0871,  0.3291],\n",
       "                       [-0.0159, -0.2811,  0.1208,  0.2998],\n",
       "                       [ 0.3673, -0.4921,  0.3373,  0.4611],\n",
       "                       [ 0.1521,  0.0898, -0.3896, -0.1208],\n",
       "                       [ 0.3125, -0.0540, -0.4903, -0.3093],\n",
       "                       [-0.4734,  0.4722, -0.1530, -0.3935],\n",
       "                       [-0.1266, -0.2689, -0.0740,  0.1983],\n",
       "                       [ 0.3780,  0.3634,  0.0243, -0.2883],\n",
       "                       [ 0.4893, -0.3309,  0.1646, -0.3657],\n",
       "                       [-0.0311,  0.2890,  0.3902,  0.4096],\n",
       "                       [ 0.4272, -0.1114,  0.1798, -0.4701],\n",
       "                       [-0.1754,  0.3692,  0.2958, -0.0522],\n",
       "                       [ 0.0715, -0.4759,  0.2870, -0.4458],\n",
       "                       [-0.2862, -0.2443,  0.3711, -0.4668],\n",
       "                       [ 0.0254, -0.4078,  0.2541, -0.1269],\n",
       "                       [-0.2617,  0.2361,  0.0602, -0.4354],\n",
       "                       [-0.2545, -0.1561, -0.1464,  0.0500],\n",
       "                       [ 0.2429,  0.3574,  0.1955, -0.3410],\n",
       "                       [ 0.4876,  0.1878,  0.1432, -0.3093],\n",
       "                       [ 0.3238,  0.0161,  0.0801, -0.0608],\n",
       "                       [-0.4688,  0.2464,  0.2722,  0.0534],\n",
       "                       [ 0.1841,  0.2556,  0.2815,  0.1601],\n",
       "                       [ 0.3349,  0.3647,  0.0167,  0.3141],\n",
       "                       [ 0.1680,  0.2077,  0.1304,  0.4223],\n",
       "                       [-0.2144, -0.3135, -0.4512,  0.0127],\n",
       "                       [-0.4471,  0.4749,  0.2171,  0.2846],\n",
       "                       [-0.3759, -0.1123,  0.2122, -0.1854],\n",
       "                       [-0.3342, -0.3016, -0.0740, -0.2901],\n",
       "                       [ 0.3840,  0.1313,  0.3962,  0.0773],\n",
       "                       [ 0.3863, -0.0318,  0.0398,  0.2997],\n",
       "                       [ 0.1648,  0.4254,  0.3741, -0.0282],\n",
       "                       [ 0.3587, -0.2200,  0.1209, -0.1125],\n",
       "                       [ 0.2432,  0.4123, -0.0254,  0.4573]])),\n",
       "              ('layer1.bias',\n",
       "               tensor([ 0.2598,  0.1393, -0.4256,  0.2105,  0.4691, -0.3150, -0.3224, -0.4305,\n",
       "                        0.2583,  0.0613,  0.4272, -0.0491,  0.4772, -0.4453,  0.1355, -0.0648,\n",
       "                        0.3203, -0.3701, -0.0445,  0.0354, -0.2003,  0.4625, -0.2262, -0.0771,\n",
       "                        0.2365,  0.3725,  0.1766,  0.2941,  0.0241, -0.4245,  0.0792,  0.2110,\n",
       "                        0.2474,  0.0889,  0.1956, -0.1283,  0.3038,  0.2141,  0.1544,  0.1937,\n",
       "                        0.3422, -0.4095,  0.0274,  0.2282,  0.0223, -0.3954,  0.1059, -0.4490,\n",
       "                       -0.3229, -0.3163, -0.1172,  0.4780,  0.2237,  0.0730,  0.0458, -0.0982,\n",
       "                       -0.0131, -0.0517, -0.1904, -0.4737,  0.0851,  0.2263, -0.1109,  0.2305])),\n",
       "              ('layer2.weight',\n",
       "               tensor([[-0.1078, -0.0399,  0.0588,  ..., -0.0229, -0.1051,  0.0454],\n",
       "                       [ 0.0279, -0.0482, -0.0803,  ..., -0.0752,  0.0939,  0.0589],\n",
       "                       [-0.0179, -0.1055,  0.1146,  ..., -0.0916,  0.0386,  0.0907],\n",
       "                       ...,\n",
       "                       [-0.0961, -0.0711, -0.0790,  ..., -0.0193, -0.1231, -0.0252],\n",
       "                       [-0.0863,  0.1140, -0.1009,  ..., -0.0038,  0.0208,  0.0623],\n",
       "                       [-0.0419, -0.0242,  0.1099,  ...,  0.1071, -0.0657, -0.0417]])),\n",
       "              ('layer2.bias',\n",
       "               tensor([-0.0127, -0.0224,  0.1055,  0.1112, -0.0351, -0.1143,  0.0267,  0.0931,\n",
       "                       -0.0531,  0.0153,  0.1000, -0.0266,  0.1154,  0.0844,  0.0380,  0.1243,\n",
       "                        0.0583,  0.0495,  0.0818,  0.0605, -0.0309, -0.0989,  0.1003, -0.1104,\n",
       "                        0.0750, -0.0482,  0.0060,  0.1106,  0.1111, -0.0689,  0.0476, -0.0112,\n",
       "                       -0.0149,  0.1005,  0.0531,  0.0199,  0.0841, -0.0741,  0.0217, -0.0643,\n",
       "                        0.0150, -0.0711,  0.1096, -0.0597,  0.1022, -0.0065, -0.1215,  0.0118,\n",
       "                        0.1007, -0.0625, -0.0259, -0.0526, -0.0504,  0.0715, -0.0012,  0.0282,\n",
       "                       -0.1128,  0.0410, -0.0433,  0.0281,  0.0640, -0.0037,  0.0515,  0.0337])),\n",
       "              ('layer3.weight',\n",
       "               tensor([[ 1.1564e-01, -2.3505e-02,  2.7769e-03, -8.9475e-02,  9.1259e-02,\n",
       "                         9.4255e-02,  1.0548e-01,  9.0256e-02, -9.5637e-02, -6.7210e-02,\n",
       "                        -3.6422e-02, -6.3144e-02,  8.2285e-03,  7.5764e-02, -9.8743e-03,\n",
       "                        -1.0561e-02, -3.2283e-02,  6.1310e-02, -5.3127e-02, -7.7819e-02,\n",
       "                        -8.9034e-03, -1.0770e-01,  1.7526e-02, -7.6782e-02,  1.0133e-01,\n",
       "                        -1.0796e-01, -4.9236e-02, -2.6364e-02,  1.2092e-01,  8.7455e-02,\n",
       "                         1.0122e-01, -1.0020e-01, -7.6420e-02,  7.9711e-02,  9.8197e-02,\n",
       "                         1.1301e-01,  1.0508e-01, -8.6559e-04, -4.0147e-02,  7.8155e-02,\n",
       "                         5.2566e-02, -1.4007e-02, -8.5266e-03,  8.7652e-02, -3.3739e-02,\n",
       "                        -2.9635e-02,  1.2888e-03, -6.8927e-02, -7.9497e-03, -5.7322e-02,\n",
       "                         5.5596e-02,  3.7335e-02,  4.8424e-02,  8.6607e-02,  9.2710e-02,\n",
       "                        -1.4398e-02, -1.9004e-02,  6.1245e-02, -2.9323e-02,  4.9083e-02,\n",
       "                         4.8886e-04, -9.4970e-02, -8.2990e-03,  6.0040e-02],\n",
       "                       [-5.0962e-02,  1.2428e-01, -1.1868e-01,  3.4372e-03,  1.0048e-01,\n",
       "                         4.3230e-02,  5.7647e-03, -2.0413e-02, -2.9559e-02,  1.2057e-01,\n",
       "                        -5.1716e-02, -5.8432e-02,  5.5154e-03, -3.6419e-02, -1.5967e-02,\n",
       "                        -8.9226e-02,  1.1185e-01,  1.0854e-01,  1.1579e-01, -7.2967e-02,\n",
       "                        -1.1048e-01,  2.9028e-02,  7.9345e-02, -1.1490e-01,  3.5393e-02,\n",
       "                        -7.7877e-02,  9.5841e-03, -5.7916e-02, -1.2529e-04,  6.7985e-02,\n",
       "                         7.8324e-02, -6.9683e-02,  7.7968e-02,  7.3786e-02,  1.7379e-02,\n",
       "                        -9.1087e-02, -3.5134e-02,  4.6268e-02, -8.2052e-02,  1.3104e-02,\n",
       "                         7.3309e-02,  2.6828e-02, -2.3986e-03, -1.0227e-02,  1.4278e-02,\n",
       "                         6.8951e-02, -5.6169e-02, -1.0612e-03,  1.2500e-01,  9.1868e-02,\n",
       "                         4.4886e-02,  1.0160e-01, -5.8486e-02, -1.0977e-01, -7.6366e-02,\n",
       "                         2.2941e-02,  8.2148e-02,  1.2494e-01, -1.1616e-02,  6.4131e-02,\n",
       "                        -1.2161e-03,  9.0400e-02, -7.9127e-02,  6.7568e-02],\n",
       "                       [ 4.4668e-02, -1.1033e-01,  1.2094e-01,  4.8220e-02,  7.3037e-02,\n",
       "                         1.7960e-02, -1.6747e-02,  9.4480e-02, -8.6491e-02,  7.1269e-02,\n",
       "                        -3.9918e-02, -1.8767e-02,  1.2032e-01,  7.8190e-03, -1.0683e-01,\n",
       "                         5.0091e-02,  1.0064e-01,  8.4653e-02, -8.6240e-02,  2.5929e-02,\n",
       "                         9.7131e-02, -6.0206e-03, -6.3372e-02,  7.5573e-02,  9.8690e-02,\n",
       "                        -8.5522e-02,  1.3415e-02,  1.4802e-02,  5.5689e-02, -1.0540e-01,\n",
       "                         1.1682e-01, -4.3313e-02, -8.4264e-02,  3.3546e-02, -3.5419e-03,\n",
       "                         1.7094e-02,  9.6926e-03, -8.8404e-02, -9.4743e-02,  9.5585e-02,\n",
       "                        -6.4967e-02, -4.1095e-02,  6.3595e-02, -2.7320e-02, -1.0248e-01,\n",
       "                        -9.3440e-02, -4.4285e-02, -1.0512e-01,  1.2236e-01,  5.3405e-02,\n",
       "                         7.1622e-02,  4.1014e-03, -5.5662e-02,  5.7388e-02, -6.6149e-02,\n",
       "                        -1.2334e-01,  4.6626e-02, -8.2600e-02, -8.6908e-02,  1.7864e-02,\n",
       "                         4.5468e-02,  3.4176e-02, -1.2214e-01,  1.0792e-01],\n",
       "                       [ 3.8622e-02, -5.1949e-02,  5.9357e-02, -7.5022e-02,  2.0100e-02,\n",
       "                        -3.2820e-02, -7.4276e-02, -6.3408e-02,  1.1141e-01, -4.9538e-02,\n",
       "                         3.2011e-02, -8.4741e-02,  1.6576e-03, -9.0417e-02,  5.8346e-02,\n",
       "                        -8.0713e-02,  7.4070e-02, -1.5485e-02, -9.2072e-02, -5.5202e-02,\n",
       "                         9.7852e-02, -1.7587e-02, -6.2813e-02, -7.4001e-02,  4.8976e-02,\n",
       "                        -3.5812e-02,  1.0006e-01, -2.5899e-02, -4.9576e-05,  8.5395e-02,\n",
       "                        -3.6221e-02, -5.9420e-03,  3.2786e-02, -4.8455e-02,  1.0497e-03,\n",
       "                         8.5000e-02,  6.0147e-03,  2.1162e-02, -2.4396e-02,  7.1273e-02,\n",
       "                         5.0370e-02, -9.5397e-02, -1.0283e-01, -1.1783e-01,  1.9839e-02,\n",
       "                         1.0227e-01,  1.0691e-01,  4.5510e-02,  1.6023e-02,  5.4844e-02,\n",
       "                        -7.7607e-02,  8.5037e-02,  8.3449e-02,  3.2522e-02, -7.0154e-02,\n",
       "                         7.0944e-02, -1.2469e-01, -8.0803e-02,  3.2509e-02, -8.5940e-02,\n",
       "                        -9.3107e-02,  1.0822e-01,  3.2186e-02,  4.6300e-02]])),\n",
       "              ('layer3.bias', tensor([-0.0970,  0.0757, -0.0623,  0.0931]))]),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor.state_dict(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01018491,  0.42836714, -0.01215711, -0.63799953], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO_version0:\n",
    "    def __init__(self,env,max_timesteps,epochs,max_iteration_episodes,gamma,clip,lr,device,num_envs,writer,minibatch_size):\n",
    "        self.env=env\n",
    "        self.actor=neural_network(self.env.single_observation_space.shape[0],self.env.single_action_space.shape[0]).to(device)\n",
    "        self.cretic=neural_network(self.env.single_observation_space.shape[0],1).to(device)\n",
    "        self.max_timesteps=max_timesteps\n",
    "        self.epochs=epochs\n",
    "        self.max_iteration_episodes=max_iteration_episodes\n",
    "        self.gamma=gamma\n",
    "        self.clip=clip\n",
    "        self.lr=lr\n",
    "        self.actor_optimization= Adam(self.actor.parameters() , lr=self.lr)\n",
    "        self.critic_optimization= Adam(self.cretic.parameters() , lr=self.lr)\n",
    "        self.cov_var=torch.full(size=(self.env.single_action_space.shape[0],),fill_value=0.5).to(device)\n",
    "        self.cov_mat=torch.diag(self.cov_var).to(device)\n",
    "        self.device=device\n",
    "        self.num_envs=num_envs\n",
    "        self.global_step=0\n",
    "        self.minibatch_size=minibatch_size\n",
    "        self.writer=writer\n",
    "    def get_action(self,state):\n",
    "        mean = self.actor(state)\n",
    "        dist = MultivariateNormal(mean, self.cov_mat)\n",
    "        action=dist.sample()\n",
    "    \n",
    "        log_probs = dist.log_prob(action)\n",
    " \n",
    "        return action, log_probs\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        t=0\n",
    "        batch_states = torch.zeros((self.max_timesteps, self.num_envs) + self.env.single_observation_space.shape).to(self.device)\n",
    "        batch_actions = torch.zeros((self.max_timesteps, self.num_envs) + self.env.single_action_space.shape).to(self.device)\n",
    "        batch_rew = torch.zeros((self.max_timesteps, self.num_envs)).to(self.device)\n",
    "        batch_done = torch.zeros((self.max_timesteps, self.num_envs)).to(self.device)\n",
    "        batch_values=torch.zeros((self.max_timesteps, self.num_envs)).to(self.device)\n",
    "        # TRY NOT TO MODIFY: start the game\n",
    "        state,_=self.env.reset()\n",
    "        next_obs = torch.Tensor(state).to(self.device)\n",
    "        next_done = torch.zeros(self.num_envs).to(self.device)\n",
    "        \n",
    "            \n",
    "        ep_lenght=0\n",
    "        ep_rew=np.zeros((self.num_envs))\n",
    "        for i in range(self.max_iteration_episodes):\n",
    "            self.global_step+=1\n",
    "            batch_states[i]=next_obs\n",
    "            V=self.evaluate_V(next_obs).flatten()\n",
    "            batch_values[i]=V\n",
    "            batch_done[i]=next_done\n",
    "            \n",
    "            action,_=self.get_action(next_obs)\n",
    "            \n",
    "            next_obs,reward,done,_,info=self.env.step(action.cpu().numpy())\n",
    "            ep_rew+=reward\n",
    "            \n",
    "            next_obs, next_done = torch.Tensor(next_obs).to(self.device), torch.Tensor(done).to(self.device)\n",
    "            batch_actions[i]=action\n",
    "            batch_rew[i] = torch.tensor(reward).to(self.device).view(-1)\n",
    "            # for item in info:\n",
    "            #     if \"episode\" in item.keys():\n",
    "            #         print(f\"global_step={t}, episodic_return={item['episode']['r']}\")\n",
    "            #         self.writer.add_scalar(\"charts/episodic_return\", item[\"episode\"][\"r\"], t)\n",
    "            #         self.writer.add_scalar(\"charts/episodic_length\", item[\"episode\"][\"l\"], t)\n",
    "            #         break\n",
    "            \n",
    "            if 1 in done or i==self.max_iteration_episodes -1:\n",
    "                print(ep_rew[0])\n",
    "                self.writer.add_scalar('charts/episodic_return',ep_rew[0],self.global_step)\n",
    "                eps_rew=np.zeros((self.num_envs))\n",
    "            state=next_obs\n",
    "            # L=[]\n",
    "            # L.append(action)\n",
    "        batch_states = batch_states.reshape((-1,) + self.env.single_observation_space.shape)\n",
    "        batch_actions = batch_actions.reshape((-1,) + self.env.single_action_space.shape)\n",
    "        \n",
    "\n",
    "        return batch_rew,batch_states,batch_actions,next_obs,next_done,batch_done,batch_values\n",
    "    \n",
    "    def evaluate_prob(self,batch_states,batch_actions):\n",
    "        mean=self.actor(batch_states)\n",
    "        dist=MultivariateNormal(mean,self.cov_mat)\n",
    "        log_prob=dist.log_prob(batch_actions)\n",
    "        V=self.cretic(batch_states).squeeze()\n",
    "        return V,log_prob\n",
    "    \n",
    "    def evaluate_V(self,batch_states):\n",
    "        V=self.cretic(batch_states)\n",
    "        return V.detach()\n",
    "    \n",
    "    def evaluate_Q(self,batch_rew,next_obs,next_done,batch_done):\n",
    "        \n",
    "        V=self.evaluate_V(next_obs).reshape(1, -1)\n",
    "       \n",
    "        batch_Q = torch.zeros_like(batch_rew).to(self.device)\n",
    "     \n",
    "        for j in reversed(range(self.max_timesteps)):\n",
    "            \n",
    "            if j==self.max_timesteps - 1:\n",
    "                nextnonterminal = 1.0 - next_done\n",
    "                next_return = V\n",
    "            else:\n",
    "                nextnonterminal = 1.0 - batch_done[j + 1]\n",
    "                next_return = batch_rew[j + 1]\n",
    "        \n",
    "            \n",
    "            batch_Q[j] = batch_rew[j] + self.gamma * nextnonterminal * next_return\n",
    "        return batch_Q.detach()\n",
    "    \n",
    "    def scale(self,A):\n",
    "        return (A-A.mean())/(A.std()+1e-10)\n",
    "        \n",
    "   \n",
    "    def learn(self,x):\n",
    "        k=0\n",
    "        while k<x:\n",
    "            batch_rew,batch_states,batch_actions,next_obs,next_done,batch_done,batch_values=self.train()\n",
    "            _,batch_log_prob=self.evaluate_prob(batch_states,batch_actions)\n",
    "            batch_log_prob=batch_log_prob.detach()\n",
    "            V_k = batch_values.detach()\n",
    "            Q=self.evaluate_Q(batch_rew,next_obs,next_done,batch_done)\n",
    "            A_k= Q -V_k\n",
    "            \n",
    "            A_k=A_k.reshape(-1)\n",
    "            batch_size=self.max_timesteps*self.num_envs\n",
    "            b_inds = np.arange(batch_size)\n",
    "            \n",
    "\n",
    "            Q=Q.reshape(-1)\n",
    "            for epoch in range(self.epochs):\n",
    "                np.random.shuffle(b_inds)\n",
    "                for start in range(0, batch_size, self.minibatch_size):\n",
    "                    end = start + self.minibatch_size\n",
    "                    mb_inds = b_inds[start:end]\n",
    "                    V,curr_log_prob=self.evaluate_prob(batch_states[mb_inds],batch_actions[mb_inds])\n",
    "                    ratio=torch.exp(curr_log_prob - batch_log_prob[mb_inds]).to(self.device)\n",
    "                    A_km=self.scale(A_k[mb_inds])\n",
    "                    loss1=ratio*A_km\n",
    "                    loss2=(torch.clamp(ratio, 1-self.clip ,1+self.clip ).to(self.device)) *A_km\n",
    "                    loss_pi=(-torch.min(loss1,loss2)).mean()\n",
    "                    \n",
    "                    self.actor_optimization.zero_grad()\n",
    "                    loss_pi.backward()\n",
    "                    self.actor_optimization.step()\n",
    "                \n",
    "                \n",
    "                    loss_v=nn.MSELoss()(V, Q[mb_inds])\n",
    "                    self.critic_optimization.zero_grad()\n",
    "                    loss_v.backward()\n",
    "                    self.critic_optimization.step()\n",
    "            k+=Q.shape[0]\n",
    "    def test(self,episodes):\n",
    "        env=gym.make('Pendulum-v1',render_mode='human')\n",
    "        for episode in range(episodes):\n",
    "            ep_len = 0            # episodic length\n",
    "            ep_ret = 0            # episodic retur\n",
    "            done=False\n",
    "            obs,_=env.reset()\n",
    "            env.render()\n",
    "            for i in range(200):\n",
    "\n",
    "                # Render environment if specified, off by default\n",
    "                \n",
    "                obs=torch.tensor(obs, dtype=torch.float).to(self.device)\n",
    "\n",
    "                # Query deterministic action from policy and run it\n",
    "                \n",
    "                action = self.actor(obs).detach().cpu().numpy()\n",
    "                \n",
    "                obs, rew, done, _,_ = env.step(action)\n",
    "\n",
    "                # Sum all episodic rewards as we go along\n",
    "                ep_ret += rew\n",
    "                \n",
    "            # Track episodic length\n",
    "\n",
    "            # returns episodic length and return in this iteration\n",
    "                print('reward :',ep_ret)\n",
    "        env.close()\n",
    "            \n",
    "        \n",
    "                \n",
    "                \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2805.7918266604074\n",
      "-4108.484640684432\n",
      "-2636.826374505506\n",
      "-3263.9824725713897\n",
      "-2977.7692220526114\n",
      "-3311.4731433883953\n",
      "-3649.6790973663237\n",
      "-3427.5252895006774\n",
      "-4013.941973625276\n",
      "-3558.1435790632495\n",
      "-3906.401093875281\n",
      "-4120.477552564103\n",
      "-4210.450514183049\n",
      "-4079.506168951416\n",
      "-3762.0381515164468\n",
      "-3996.2298326903606\n",
      "-4254.276974602877\n",
      "-3928.0589535118306\n",
      "-4127.515475835314\n",
      "-4049.6310945800537\n",
      "-3933.3666469669615\n",
      "-3998.0030869080883\n",
      "-4057.238287447978\n",
      "-3994.570023893927\n",
      "-3720.6906389876754\n",
      "-3756.721738699099\n",
      "-3724.866697308157\n",
      "-3696.1716324909044\n",
      "-3672.946847351104\n",
      "-3686.4618546729803\n",
      "-3789.546991797239\n",
      "-3630.813061802538\n",
      "-3617.2164741504766\n",
      "-3590.9858724982228\n",
      "-3722.9727111015745\n",
      "-3688.246552546248\n",
      "-3562.766922067194\n",
      "-3579.1196060685274\n",
      "-3520.039722025734\n",
      "-3804.05751295162\n",
      "-3740.9799265410097\n",
      "-3627.445400100638\n",
      "-3612.1556575993327\n",
      "-3674.536686192134\n",
      "-3759.7955523742626\n",
      "-3236.108044573208\n",
      "-3689.7740140878873\n",
      "-3663.365725370989\n",
      "-3634.1680837188383\n",
      "-3660.229337316839\n",
      "-3604.9008555923137\n",
      "-3598.5448432223543\n",
      "-3766.071523780698\n",
      "-3658.1678042615836\n",
      "-3648.7283014525287\n",
      "-3748.9513590167244\n",
      "-3531.3065804612897\n",
      "-3734.0674579106953\n",
      "-3657.2917108882407\n",
      "-3643.787537949787\n",
      "-3744.4274876036457\n",
      "-3692.8730414812812\n",
      "-3727.003539640376\n",
      "-3705.3673570458864\n",
      "-3419.3902674735045\n",
      "-3695.001250197218\n",
      "-3706.788994949476\n",
      "-3463.27396064926\n",
      "-3747.18456155561\n",
      "-3654.7756241557886\n",
      "-3610.728438031418\n",
      "-3671.8462663383953\n",
      "-3704.941733415018\n",
      "-3586.252924409807\n",
      "-3693.0721988943023\n",
      "-3565.169491141205\n",
      "-3734.2262656745947\n",
      "-3783.932174080373\n",
      "-3764.6586635321687\n",
      "-3319.9466236688945\n",
      "-3720.6496759737993\n",
      "-3415.670152049547\n",
      "-3627.937346619057\n",
      "-3618.869279904976\n",
      "-3622.432918299941\n",
      "-3739.701116434153\n",
      "-3613.087188860902\n",
      "-3663.8095564004125\n",
      "-3738.24728023131\n",
      "-3515.639254421775\n",
      "-3642.073910621225\n",
      "-3620.754903950213\n",
      "-3578.3983434751167\n",
      "-3677.480618930186\n",
      "-3661.091164488336\n",
      "-3422.2281409161756\n",
      "-3710.21132137063\n",
      "-3576.5225111175873\n",
      "-3587.2247719152615\n",
      "-3433.4923060906317\n",
      "-3692.499841580199\n",
      "-3523.761259748507\n",
      "-3697.7352707722653\n",
      "-3769.975093066574\n",
      "-3602.6973272549913\n",
      "-3550.5997811473108\n",
      "-3559.9291272936957\n",
      "-3737.2135532226944\n",
      "-3641.2810579930674\n",
      "-3611.9103513195614\n",
      "-3613.295692239825\n",
      "-3750.719190891593\n",
      "-3644.251497020721\n",
      "-3441.7160238578967\n",
      "-3571.8851407855996\n",
      "-3630.2535171877007\n",
      "-3660.375516451486\n",
      "-3577.9945168115796\n",
      "-3682.8601973461405\n",
      "-3713.375656662872\n",
      "-3490.0628605005927\n",
      "-3621.8200034672186\n",
      "-3722.490770728736\n",
      "-3707.4584612029694\n",
      "-3508.2178688844324\n",
      "-3682.70177118992\n",
      "-3641.4663082068187\n",
      "-3627.8559225318686\n",
      "-3660.0835000863767\n",
      "-3704.0822741838247\n",
      "-3601.8488565486487\n",
      "-3645.6317035266593\n",
      "-3590.6204818513797\n",
      "-3513.316267805428\n",
      "-3512.8561834749307\n",
      "-3585.0093873800142\n",
      "-3610.8882970928653\n",
      "-3705.7890928316624\n",
      "-3748.37421418105\n",
      "-3686.5095174061935\n",
      "-3625.6748983665284\n",
      "-3517.7333132306203\n",
      "-3595.9735278228663\n",
      "-3658.026464993889\n",
      "-3581.7032301919376\n",
      "-3642.015399831205\n",
      "-3653.1182527869246\n",
      "-3525.642246932821\n",
      "-3720.7676864143095\n",
      "-3620.776273984795\n",
      "-3558.033684856939\n",
      "-3696.5343684115746\n",
      "-3471.520259385725\n",
      "-3527.016387988041\n",
      "-3614.7730331986263\n",
      "-3523.1966794708937\n",
      "-3699.9898663615304\n",
      "-3672.788345743714\n",
      "-3663.4033077263243\n",
      "-3765.953469863532\n",
      "-3696.3777390019563\n",
      "-3532.9619111180027\n",
      "-3709.8570659396983\n",
      "-3572.8402416897993\n",
      "-3583.242375310975\n",
      "-3607.309899572728\n",
      "-3648.2637521995175\n",
      "-3509.2528891746388\n",
      "-3644.9917643561535\n",
      "-3626.599977980646\n",
      "-3665.322828849458\n",
      "-3642.6679549406877\n",
      "-3488.9547917504583\n",
      "-3606.4197587388862\n",
      "-3567.2149128791866\n",
      "-3600.9723963221395\n",
      "-3635.5899001605812\n",
      "-3707.7787211138616\n",
      "-3677.7438950236888\n",
      "-3745.7716235795033\n",
      "-3609.640007670416\n",
      "-3674.2017608414435\n",
      "-3192.4744559691976\n",
      "-3548.098920721525\n",
      "-3636.041226749058\n",
      "-3698.648498610464\n",
      "-3718.7170148897435\n",
      "-3582.5863170125003\n",
      "-3425.263681539017\n",
      "-3576.4013888977775\n",
      "-3401.525273754482\n",
      "-3440.4011386089833\n",
      "-3329.2710978167133\n",
      "-3597.1143371501407\n",
      "-3728.224169188006\n",
      "-3495.793589661877\n",
      "-3636.8389388439937\n",
      "-3444.693962250978\n",
      "-3427.533808756227\n",
      "-3664.8596066261916\n",
      "-3560.7542818123675\n",
      "-3701.841654135963\n",
      "-3590.7659622855303\n",
      "-3685.6540206094373\n",
      "-3599.8646435524333\n",
      "-3683.7641910498473\n",
      "-3749.1466123727596\n"
     ]
    }
   ],
   "source": [
    "def make_env(gym_id):\n",
    "    def thunk():\n",
    "        env = gym.make(gym_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "      \n",
    "        return env\n",
    "\n",
    "    return thunk\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "        [make_env(\"Pendulum-v1\")for i in range(1)])\n",
    "device = torch.device(\"cuda\")\n",
    "writer = SummaryWriter(\"raed8/PPO_version1\")\n",
    "\n",
    "model=PPO_version0(envs,1_000,10,500,0.99,0.2,3e-4,device,1,writer,4)\n",
    "model.learn(1_000_000)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PPO_version0' object has no attribute 'writer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mwriter\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PPO_version0' object has no attribute 'writer'"
     ]
    }
   ],
   "source": [
    "model.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_states = torch.zeros((15, 3)).detach()\n",
    "n=neural_network(envs.single_observation_space.shape[0],1)\n",
    "n(batch_states).squeeze().requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_states = torch.zeros((15, 3)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_states.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward : -2.8855900563785033\n",
      "reward : -5.924633123417365\n",
      "reward : -9.229213241518249\n",
      "reward : -12.921749766383574\n",
      "reward : -17.127221707126424\n",
      "reward : -21.969624751952214\n",
      "reward : -27.565531507796987\n",
      "reward : -34.01505136830031\n",
      "reward : -41.39146560955585\n",
      "reward : -49.73176037704587\n",
      "reward : -59.030625473741516\n",
      "reward : -69.23974906789809\n",
      "reward : -79.86609383490584\n",
      "reward : -89.46169045443483\n",
      "reward : -98.15804413684744\n",
      "reward : -106.12519067494951\n",
      "reward : -113.57245531569336\n",
      "reward : -120.65264535025136\n",
      "reward : -127.43297525421019\n",
      "reward : -133.9512890354431\n",
      "reward : -140.24086925534712\n",
      "reward : -146.34245749315576\n",
      "reward : -152.30285472588002\n",
      "reward : -158.17340407852637\n",
      "reward : -164.0084154925818\n",
      "reward : -169.86356137640416\n",
      "reward : -175.79424538005188\n",
      "reward : -181.85393267817477\n",
      "reward : -188.09243510464887\n",
      "reward : -194.55416844858453\n",
      "reward : -201.2764368522924\n",
      "reward : -208.28784019262858\n",
      "reward : -215.60693123797998\n",
      "reward : -223.2412576303341\n",
      "reward : -231.18690213431313\n",
      "reward : -239.42858511947122\n",
      "reward : -247.9403276372214\n",
      "reward : -256.6866093023164\n",
      "reward : -265.6239089669657\n",
      "reward : -274.7024968095528\n",
      "reward : -283.8683528741932\n",
      "reward : -293.0651106966932\n",
      "reward : -302.2359545777154\n",
      "reward : -311.32542676402255\n",
      "reward : -320.28112167597027\n",
      "reward : -329.05525665046815\n",
      "reward : -337.6060332681555\n",
      "reward : -345.89863532885204\n",
      "reward : -353.91084516098135\n",
      "reward : -361.6355532963962\n",
      "reward : -369.0760767572651\n",
      "reward : -376.2421295598746\n",
      "reward : -383.14756498563565\n",
      "reward : -389.8124670536448\n",
      "reward : -396.26492490655966\n",
      "reward : -402.54003608920925\n",
      "reward : -408.6787037007817\n",
      "reward : -414.7262942308722\n",
      "reward : -420.7312106742303\n",
      "reward : -426.74341574144694\n",
      "reward : -432.8129206503209\n",
      "reward : -438.9882435545986\n",
      "reward : -445.31484299568433\n",
      "reward : -451.83354684956095\n",
      "reward : -458.57902280490134\n",
      "reward : -465.57836532526466\n",
      "reward : -472.84989683914694\n",
      "reward : -480.40228832635165\n",
      "reward : -488.23409075369415\n",
      "reward : -496.33373433233953\n",
      "reward : -504.68000451282626\n",
      "reward : -513.2429538259512\n",
      "reward : -521.9851692028187\n",
      "reward : -530.8632931106507\n",
      "reward : -539.8296949836262\n",
      "reward : -548.8342024860387\n",
      "reward : -557.82582283626\n",
      "reward : -566.7544059305488\n",
      "reward : -575.5722187527654\n",
      "reward : -584.2354121768145\n",
      "reward : -592.7053657587626\n",
      "reward : -600.9498933383167\n",
      "reward : -608.9441813029597\n",
      "reward : -616.6720568288008\n",
      "reward : -624.1278243855439\n",
      "reward : -631.3151993590191\n",
      "reward : -638.2452539977977\n",
      "reward : -644.9372012187092\n",
      "reward : -651.4181868530633\n",
      "reward : -657.7223277485837\n",
      "reward : -663.8895417386302\n",
      "reward : -669.9642343068017\n",
      "reward : -675.9938961142856\n",
      "reward : -682.0276472303755\n",
      "reward : -688.1147454660241\n",
      "reward : -694.303064859763\n",
      "reward : -700.6375509319136\n",
      "reward : -707.1586729974536\n",
      "reward : -713.9009177008019\n",
      "reward : -720.8913953791617\n",
      "reward : -728.1486529116869\n",
      "reward : -735.6817945033846\n",
      "reward : -743.4899996658306\n",
      "reward : -751.5624955043248\n",
      "reward : -759.8789947934633\n",
      "reward : -768.4105632736928\n",
      "reward : -777.1208407080818\n",
      "reward : -785.9675183161143\n",
      "reward : -794.903971919362\n",
      "reward : -803.8809615633045\n",
      "reward : -812.8483277258473\n",
      "reward : -821.7566348939218\n",
      "reward : -830.5587306897753\n",
      "reward : -839.2112003933457\n",
      "reward : -847.6757015603338\n",
      "reward : -855.9201613079484\n",
      "reward : -863.9198108053075\n",
      "reward : -871.657892929416\n",
      "reward : -879.1271077287462\n",
      "reward : -886.3293900207193\n",
      "reward : -893.2748339149671\n",
      "reward : -899.9821238307429\n",
      "reward : -906.4778829575009\n",
      "reward : -912.7957295010582\n",
      "reward : -918.9751221028406\n",
      "reward : -925.0600588115852\n",
      "reward : -931.0976841298352\n",
      "reward : -937.1368408882323\n",
      "reward : -943.2265854084529\n",
      "reward : -949.41467277428\n",
      "reward : -955.7460189583005\n",
      "reward : -962.2611594226792\n",
      "reward : -968.9947469553107\n",
      "reward : -975.9741585368018\n",
      "reward : -983.2183031876125\n",
      "reward : -990.7367312112667\n",
      "reward : -998.5291341790676\n",
      "reward : -1006.5852940958449\n",
      "reward : -1014.8854955420701\n",
      "reward : -1023.4013669440972\n",
      "reward : -1032.0970779640556\n",
      "reward : -1040.93079729808\n",
      "reward : -1049.8563109150355\n",
      "reward : -1058.8247113455059\n",
      "reward : -1067.7860874334585\n",
      "reward : -1076.6911644230715\n",
      "reward : -1085.4928617008593\n",
      "reward : -1094.147747395704\n",
      "reward : -1102.6173742245442\n",
      "reward : -1110.8694792482302\n",
      "reward : -1118.879022567255\n",
      "reward : -1126.6289561621684\n",
      "reward : -1134.111318840716\n",
      "reward : -1141.3272290917362\n",
      "reward : -1148.2862952798878\n",
      "reward : -1155.006738416182\n",
      "reward : -1161.514737399405\n",
      "reward : -1167.843500386545\n",
      "reward : -1174.032122553589\n",
      "reward : -1180.124294423555\n",
      "reward : -1186.1669157552549\n",
      "reward : -1192.2086526273595\n",
      "reward : -1198.298457092008\n",
      "reward : -1204.4840567898\n",
      "reward : -1210.810421240279\n",
      "reward : -1217.3182237009373\n",
      "reward : -1224.0423400648754\n",
      "reward : -1231.0104530652416\n",
      "reward : -1238.2418524391242\n",
      "reward : -1245.7465308773576\n",
      "reward : -1253.5246655448582\n",
      "reward : -1261.566545103992\n",
      "reward : -1269.8529582699807\n",
      "reward : -1278.3560124722121\n",
      "reward : -1287.040311639936\n",
      "reward : -1295.8643986341353\n",
      "reward : -1304.782362698888\n",
      "reward : -1313.745522163288\n",
      "reward : -1322.704111016927\n",
      "reward : -1331.6089183343686\n",
      "reward : -1340.412847082685\n",
      "reward : -1349.072370971983\n",
      "reward : -1357.54887351577\n",
      "reward : -1365.809852102778\n",
      "reward : -1373.8299625685795\n",
      "reward : -1381.5918267028921\n",
      "reward : -1389.086932459092\n",
      "reward : -1396.315771076867\n",
      "reward : -1403.2875121461211\n",
      "reward : -1410.019948071026\n",
      "reward : -1416.538854924375\n",
      "reward : -1422.8770773761164\n",
      "reward : -1429.0733971894208\n",
      "reward : -1435.1712493758214\n",
      "reward : -1441.21734152754\n",
      "reward : -1447.260214826309\n",
      "reward : -1453.348766945389\n",
      "reward : -1459.5307447169193\n",
      "reward : -1465.8512131725201\n",
      "reward : -1472.3510191084436\n",
      "reward : -5.207270517211405\n",
      "reward : -10.735340903750958\n",
      "reward : -16.657316003961544\n",
      "reward : -23.035279771286667\n",
      "reward : -29.91685368272322\n",
      "reward : -37.33204498192673\n",
      "reward : -45.290909761088656\n",
      "reward : -53.78248045829166\n",
      "reward : -62.77518250643256\n",
      "reward : -72.21866271102948\n",
      "reward : -82.04379879257615\n",
      "reward : -91.93753201150487\n",
      "reward : -101.41811372170196\n",
      "reward : -110.51462849771598\n",
      "reward : -119.2482467572147\n",
      "reward : -127.63683376220511\n",
      "reward : -135.69666463637927\n",
      "reward : -143.44327315274407\n",
      "reward : -150.89222159570986\n",
      "reward : -158.05963346026186\n",
      "reward : -164.96186379029396\n",
      "reward : -171.61915239714835\n",
      "reward : -178.0598875742087\n",
      "reward : -184.31959501278286\n",
      "reward : -190.43971694367656\n",
      "reward : -196.46625080801456\n",
      "reward : -202.4483038996415\n",
      "reward : -208.4365994860181\n",
      "reward : -214.48194930957868\n",
      "reward : -220.63369495397913\n",
      "reward : -226.93812148757837\n",
      "reward : -233.43686223165372\n",
      "reward : -240.16534014447817\n",
      "reward : -247.151321818892\n",
      "reward : -254.4136845641302\n",
      "reward : -261.96150570980893\n",
      "reward : -269.7935698771716\n",
      "reward : -277.8983546670295\n",
      "reward : -286.25450539181526\n",
      "reward : -294.8317575114003\n",
      "reward : -303.5922240998693\n",
      "reward : -312.49194334348533\n",
      "reward : -321.4825791535753\n",
      "reward : -330.51318171900334\n",
      "reward : -339.5319365305656\n",
      "reward : -348.4878529111464\n",
      "reward : -357.33236160982995\n",
      "reward : -366.0208031580696\n",
      "reward : -374.5137934282637\n",
      "reward : -382.7784499928348\n",
      "reward : -390.7891951785416\n",
      "reward : -398.5299950445487\n",
      "reward : -405.996186681942\n",
      "reward : -413.1923188815913\n",
      "reward : -420.12971500000253\n",
      "reward : -426.82735229327517\n",
      "reward : -433.31219720246196\n",
      "reward : -439.6182483299777\n",
      "reward : -445.78536838076684\n",
      "reward : -451.8579705358903\n",
      "reward : -457.88361430245925\n",
      "reward : -463.9115474682943\n",
      "reward : -469.9912119829852\n",
      "reward : -476.17071971857393\n",
      "reward : -482.49530412222094\n",
      "reward : -489.00576711225693\n",
      "reward : -495.7369644068293\n",
      "reward : -502.716400244025\n",
      "reward : -509.96302515213176\n",
      "reward : -517.4863390393111\n",
      "reward : -525.2858904321173\n",
      "reward : -533.3512309612576\n",
      "reward : -541.6623385011152\n",
      "reward : -550.190473784274\n",
      "reward : -558.8993956012819\n",
      "reward : -567.7468369520816\n",
      "reward : -576.6861406465076\n",
      "reward : -585.6679640327835\n",
      "reward : -594.6419819334988\n",
      "reward : -603.5585377799623\n",
      "reward : -612.3702106483827\n",
      "reward : -621.0332778797491\n",
      "reward : -629.5090580973863\n",
      "reward : -637.7651175137953\n",
      "reward : -645.77631445195\n",
      "reward : -653.525483461601\n",
      "reward : -661.0050937847225\n",
      "reward : -668.2171112190147\n",
      "reward : -675.1715156780925\n",
      "reward : -681.8866944488645\n",
      "reward : -688.38901124032\n",
      "reward : -694.7118706214201\n",
      "reward : -700.8945690308366\n",
      "reward : -706.9809970019421\n",
      "reward : -713.0182477692838\n",
      "reward : -719.0551697616092\n",
      "reward : -725.1408820127984\n",
      "reward : -731.3232594784394\n",
      "reward : -737.6473946777227\n",
      "reward : -744.1540545141293\n",
      "reward : -750.8781740404897\n",
      "reward : -757.8474560521342\n",
      "reward : -765.0811679754228\n",
      "reward : -772.5892366837953\n",
      "reward : -780.371731584129\n",
      "reward : -788.4187960290562\n",
      "reward : -796.711042711038\n",
      "reward : -805.2203808369854\n",
      "reward : -813.9112031387612\n",
      "reward : -822.7418373357266\n",
      "reward : -831.6661617595906\n",
      "reward : -840.6352950254682\n",
      "reward : -849.5992883099605\n",
      "reward : -858.5087693457766\n",
      "reward : -867.3165048995263\n",
      "reward : -875.9788606411122\n",
      "reward : -884.4571427674701\n",
      "reward : -892.7188042630614\n",
      "reward : -900.7384912015393\n",
      "reward : -908.4988146016221\n",
      "reward : -915.991497299713\n",
      "reward : -923.2173511831274\n",
      "reward : -930.1856526614895\n",
      "reward : -936.9143156808816\n",
      "reward : -943.4292479075013\n",
      "reward : -949.7634307892621\n",
      "reward : -955.9557834198525\n",
      "reward : -962.049874589191\n",
      "reward : -968.0925386251353\n",
      "reward : -974.1324334123487\n",
      "reward : -980.2185605608447\n",
      "reward : -986.398755328938\n",
      "reward : -992.7181527321247\n",
      "reward : -999.2176479949055\n",
      "reward : -1005.9323918191351\n",
      "reward : -1012.8903877882948\n",
      "reward : -1020.1112820092088\n",
      "reward : -1027.6054449481228\n",
      "reward : -1035.3734361646416\n",
      "reward : -1043.4059134459148\n",
      "reward : -1051.6840042326785\n",
      "reward : -1060.1801096086524\n",
      "reward : -1068.8590710182798\n",
      "reward : -1077.6796056515277\n",
      "reward : -1086.5959106200269\n",
      "reward : -1095.5593454732968\n",
      "reward : -1104.5201208401782\n",
      "reward : -1113.4289413994875\n",
      "reward : -1122.2385691393517\n",
      "reward : -1130.9052852448394\n",
      "reward : -1139.390234730329\n",
      "reward : -1147.6606368173314\n",
      "reward : -1155.6908369156474\n",
      "reward : -1163.4631197801841\n",
      "reward : -1170.9686425222606\n",
      "reward : -1178.207568303087\n",
      "reward : -1185.18872956116\n",
      "reward : -1191.9296050183889\n",
      "reward : -1198.4556917640648\n",
      "reward : -1204.7995992148785\n",
      "reward : -1210.9999240604302\n",
      "reward : -1217.0999704511328\n",
      "reward : -1223.146371534272\n",
      "reward : -1229.1876515886684\n",
      "reward : -1235.272749593971\n",
      "reward : -1241.4495123533825\n",
      "reward : -1247.763163529787\n",
      "reward : -1254.254766033715\n",
      "reward : -1260.959717011122\n",
      "reward : -1267.9063413440401\n",
      "reward : -1275.114672623276\n",
      "reward : -1282.5955211118226\n",
      "reward : -1290.349919949643\n",
      "reward : -1298.3690126299991\n",
      "reward : -1306.6344018253915\n",
      "reward : -1315.1189321423826\n",
      "reward : -1323.7878388474828\n",
      "reward : -1332.6001695863738\n",
      "reward : -1341.5103794401768\n",
      "reward : -1350.4700084085262\n",
      "reward : -1359.4293682767727\n",
      "reward : -1368.3391861699267\n",
      "reward : -1377.1521699846567\n",
      "reward : -1385.824473523165\n",
      "reward : -1394.3170452460906\n",
      "reward : -1402.596843784695\n",
      "reward : -1410.6378965024333\n",
      "reward : -1418.422143081118\n",
      "reward : -1425.940232106876\n",
      "reward : -1433.191765023152\n",
      "reward : -1440.185148223245\n",
      "reward : -1446.9374487382217\n",
      "reward : -1453.47378130247\n",
      "reward : -1459.8264151554722\n",
      "reward : -1466.0336589729009\n",
      "reward : -1472.1385881350454\n",
      "reward : -1478.187670977557\n",
      "reward : -1484.229334132865\n",
      "reward : -1490.312488619745\n",
      "reward : -1496.4850252571207\n",
      "reward : -0.35686374312200564\n",
      "reward : -0.7770044010337636\n",
      "reward : -1.2782127587147094\n",
      "reward : -1.8845182556132374\n",
      "reward : -2.628321823078964\n",
      "reward : -3.553108004848362\n",
      "reward : -4.7167797156955995\n",
      "reward : -6.195530755282421\n",
      "reward : -8.087917169539706\n",
      "reward : -10.518354013096625\n",
      "reward : -13.638629939185892\n",
      "reward : -17.625305852757485\n",
      "reward : -22.670421662151412\n",
      "reward : -28.963517709886183\n",
      "reward : -36.66545946951473\n",
      "reward : -45.879038620572075\n",
      "reward : -56.62582712881573\n",
      "reward : -68.8392236136718\n",
      "reward : -80.00281162953463\n",
      "reward : -89.47201242307555\n",
      "reward : -97.41047216442747\n",
      "reward : -104.0560237231681\n",
      "reward : -109.70473511768921\n",
      "reward : -114.68818040898427\n",
      "reward : -119.3432730062701\n",
      "reward : -123.8071479491387\n",
      "reward : -128.17549071170063\n",
      "reward : -132.54614706050486\n",
      "reward : -137.0176850809132\n",
      "reward : -141.6879527963018\n",
      "reward : -146.6522559753255\n",
      "reward : -152.0008466108811\n",
      "reward : -157.81557731686615\n",
      "reward : -164.16583043432868\n",
      "reward : -171.10413040805116\n",
      "reward : -178.66210726135964\n",
      "reward : -186.847583547097\n",
      "reward : -195.6434197790726\n",
      "reward : -205.00838268592392\n",
      "reward : -214.87982883692774\n",
      "reward : -224.8794718007556\n",
      "reward : -234.37085005039341\n",
      "reward : -243.48326434317954\n",
      "reward : -252.36403974931414\n",
      "reward : -261.1724773905936\n",
      "reward : -270.07296400529594\n",
      "reward : -279.2251815111039\n",
      "reward : -288.72486659624855\n",
      "reward : -298.59979683508755\n",
      "reward : -308.36087236561974\n",
      "reward : -317.7589888440756\n",
      "reward : -326.7978689101521\n",
      "reward : -335.48672557432593\n",
      "reward : -343.8375401048345\n",
      "reward : -351.86368587944514\n",
      "reward : -359.579329407217\n",
      "reward : -366.99942496672514\n",
      "reward : -374.13983211836495\n",
      "reward : -381.01714487045894\n",
      "reward : -387.65242990441675\n",
      "reward : -394.07479897963253\n",
      "reward : -400.3203754428711\n",
      "reward : -406.431058374831\n",
      "reward : -412.4531527117439\n",
      "reward : -418.43591975868895\n",
      "reward : -424.43008134682583\n",
      "reward : -430.4862909043022\n",
      "reward : -436.6535735414709\n",
      "reward : -442.9777396708437\n",
      "reward : -449.4997934032106\n",
      "reward : -456.25438425350814\n",
      "reward : -463.2683808938339\n",
      "reward : -470.55966883042026\n",
      "reward : -478.1362804331934\n",
      "reward : -485.99595003338766\n",
      "reward : -494.1261497281239\n",
      "reward : -502.5046110881881\n",
      "reward : -511.1002867450246\n",
      "reward : -519.8746663014716\n",
      "reward : -528.7833408574281\n",
      "reward : -537.7777103616979\n",
      "reward : -546.8067428121263\n",
      "reward : -555.8187162932147\n",
      "reward : -564.7628970149077\n",
      "reward : -573.5911244066235\n",
      "reward : -582.259285707108\n",
      "reward : -590.7286664525943\n",
      "reward : -598.9671597125828\n",
      "reward : -606.9500296374073\n",
      "reward : -614.662267712081\n",
      "reward : -622.1002463204218\n",
      "reward : -629.2691220110315\n",
      "reward : -636.180825651754\n",
      "reward : -642.85519330556\n",
      "reward : -649.3199633190131\n",
      "reward : -655.6097945282478\n",
      "reward : -661.7650802860937\n",
      "reward : -667.8306232589797\n",
      "reward : -673.8542243907405\n",
      "reward : -679.8852206091667\n",
      "reward : -685.9729874462057\n",
      "reward : -692.1654119259919\n",
      "reward : -698.507342507368\n",
      "reward : -705.0390374854825\n",
      "reward : -711.7946578580899\n",
      "reward : -718.8008783480334\n",
      "reward : -726.0757119124066\n",
      "reward : -733.6276498110483\n",
      "reward : -741.4552056767186\n",
      "reward : -749.5469184649916\n",
      "reward : -757.881822612781\n",
      "reward : -766.4303455503826\n",
      "reward : -775.1555544686603\n",
      "reward : -784.0146534651925\n",
      "reward : -792.9606301274918\n",
      "reward : -801.9439629748084\n",
      "reward : -810.9143210203869\n",
      "reward : -819.8222074746635\n",
      "reward : -828.6205168177897\n",
      "reward : -837.2659857777802\n",
      "reward : -845.7205231508447\n",
      "reward : -853.9524007818712\n",
      "reward : -861.9372795652665\n",
      "reward : -869.6588637137667\n",
      "reward : -877.1106030479098\n",
      "reward : -884.295320373142\n",
      "reward : -891.2237317228619\n",
      "reward : -897.9150958484875\n",
      "reward : -904.3965691761167\n",
      "reward : -910.7022444174572\n",
      "reward : -916.8719823694098\n",
      "reward : -922.9501012293429\n",
      "reward : -928.9839771052643\n",
      "reward : -935.0225912446003\n",
      "reward : -941.1150413304821\n",
      "reward : -947.3090231169875\n",
      "reward : -953.6492894360916\n",
      "reward : -960.1761073332177\n",
      "reward : -966.923757832201\n",
      "reward : -973.9191499779475\n",
      "reward : -981.1806424576084\n",
      "reward : -988.717173503757\n",
      "reward : -996.5277873453656\n",
      "reward : -1004.601613306035\n",
      "reward : -1012.9183082656591\n",
      "reward : -1021.4489255806469\n",
      "reward : -1030.1571351351529\n",
      "reward : -1039.0006976408063\n",
      "reward : -1047.933093198121\n",
      "reward : -1056.905215547877\n",
      "reward : -1065.8670626422852\n",
      "reward : -1074.7693746400462\n",
      "reward : -1083.5651876390873\n",
      "reward : -1092.2112829682346\n",
      "reward : -1100.669516600616\n",
      "reward : -1108.9080110750763\n",
      "reward : -1116.9021843160394\n",
      "reward : -1124.6354850535345\n",
      "reward : -1132.1006097209156\n",
      "reward : -1139.2993926898116\n",
      "reward : -1146.2420200995064\n",
      "reward : -1152.9472654133158\n",
      "reward : -1159.441814748658\n",
      "reward : -1165.759321554183\n",
      "reward : -1171.9392517076697\n",
      "reward : -1178.0255831048532\n",
      "reward : -1184.0654138723366\n",
      "reward : -1190.1075156287764\n",
      "reward : -1196.2008500992758\n",
      "reward : -1202.393055973115\n",
      "reward : -1208.728913031842\n",
      "reward : -1215.2488035693668\n",
      "reward : -1221.98721425697\n",
      "reward : -1228.9713484748668\n",
      "reward : -1236.219940991652\n",
      "reward : -1243.7423749890384\n",
      "reward : -1251.538190057882\n",
      "reward : -1259.5970387386672\n",
      "reward : -1267.8991046012623\n",
      "reward : -1276.4159474760847\n",
      "reward : -1285.1117026545078\n",
      "reward : -1293.944538523144\n",
      "reward : -1302.868273075795\n",
      "reward : -1311.8340604089324\n",
      "reward : -1320.79207706548\n",
      "reward : -1329.69315843349\n",
      "reward : -1338.490352711372\n",
      "reward : -1347.1403716967743\n",
      "reward : -1355.6049227250521\n",
      "reward : -1363.851904280928\n",
      "reward : -1371.856440156006\n",
      "reward : -1379.6016601019805\n",
      "reward : -1387.0796760606015\n",
      "reward : -1394.291642170697\n",
      "reward : -1401.2472958062297\n",
      "reward : -1407.9649687768804\n",
      "reward : -1414.470928758769\n",
      "reward : -1420.7984480720158\n",
      "reward : -1426.9866600724736\n",
      "reward : -1433.0792671178347\n",
      "reward : -2.7388502943318427\n",
      "reward : -5.807668294836415\n",
      "reward : -9.333254322070092\n",
      "reward : -13.447948315361781\n",
      "reward : -18.285165685046774\n",
      "reward : -23.971240280716184\n",
      "reward : -30.614003268059314\n",
      "reward : -38.28986215226769\n",
      "reward : -47.03241905685516\n",
      "reward : -56.826018059371236\n",
      "reward : -67.60636218296337\n",
      "reward : -77.94728780197778\n",
      "reward : -87.17178559016058\n",
      "reward : -95.43145510415364\n",
      "reward : -102.92036166578511\n",
      "reward : -109.87540361663987\n",
      "reward : -116.47443494042682\n",
      "reward : -122.79351278160156\n",
      "reward : -128.8783082108158\n",
      "reward : -134.77649349412553\n",
      "reward : -140.54163022117973\n",
      "reward : -146.2314861396304\n",
      "reward : -151.90633508199068\n",
      "reward : -157.62725014200902\n",
      "reward : -163.45436877460543\n",
      "reward : -169.4450983308586\n",
      "reward : -175.65224631645893\n",
      "reward : -182.12209918334403\n",
      "reward : -188.89252753650712\n",
      "reward : -195.99124905038315\n",
      "reward : -203.43441499504198\n",
      "reward : -211.22568653138384\n",
      "reward : -219.35592653947418\n",
      "reward : -227.80355908376447\n",
      "reward : -236.53556164106521\n",
      "reward : -245.5089798782737\n",
      "reward : -254.6728104703972\n",
      "reward : -263.9700904120713\n",
      "reward : -273.340054100943\n",
      "reward : -282.7202573522083\n",
      "reward : -292.0486063284988\n",
      "reward : -301.26526068710956\n",
      "reward : -310.314401229414\n",
      "reward : -319.14549122270535\n",
      "reward : -327.71622544244985\n",
      "reward : -335.99918168790225\n",
      "reward : -343.9842557512211\n",
      "reward : -351.67279979673407\n",
      "reward : -359.07334947701827\n",
      "reward : -366.1985698980548\n",
      "reward : -373.0640014163557\n",
      "reward : -379.6910818193931\n",
      "reward : -386.1091699273394\n",
      "reward : -392.3545070269374\n",
      "reward : -398.4689815378057\n",
      "reward : -404.49876352021795\n",
      "reward : -410.492861506216\n",
      "reward : -416.50163344359936\n",
      "reward : -422.5752645208317\n",
      "reward : -428.76221460742056\n",
      "reward : -435.10764142525665\n",
      "reward : -441.6518227613833\n",
      "reward : -448.4286280984608\n",
      "reward : -455.4641192684637\n",
      "reward : -462.7753813265044\n",
      "reward : -470.3696896754754\n",
      "reward : -478.244102412797\n",
      "reward : -486.3855293074828\n",
      "reward : -494.77127895949303\n",
      "reward : -503.37003594677145\n",
      "reward : -512.1431820783779\n",
      "reward : -521.0463573279711\n",
      "reward : -530.0311568935033\n",
      "reward : -539.0468758397369\n",
      "reward : -548.0422343794919\n",
      "reward : -556.9670383757677\n",
      "reward : -565.7737468355439\n",
      "reward : -574.4189289104531\n",
      "reward : -582.8645963536039\n",
      "reward : -591.0793934980594\n",
      "reward : -599.0394059827108\n",
      "reward : -606.7301077459323\n",
      "reward : -614.147911463572\n",
      "reward : -621.2979057868946\n",
      "reward : -628.1922379518642\n",
      "reward : -634.8513204895445\n",
      "reward : -641.3033946940819\n",
      "reward : -647.5835332658572\n",
      "reward : -653.7324438164313\n",
      "reward : -659.7951375479497\n",
      "reward : -665.8195151779703\n",
      "reward : -671.8549032196444\n",
      "reward : -677.9505557446928\n",
      "reward : -684.1541267718372\n",
      "reward : -690.5101208390163\n",
      "reward : -697.058344767778\n",
      "reward : -703.8324086244138\n",
      "reward : -710.8583513251717\n",
      "reward : -718.1534870506655\n",
      "reward : -725.7255739562693\n",
      "reward : -733.572391504079\n",
      "reward : -741.6817780249373\n",
      "reward : -750.0321331926889\n",
      "reward : -758.5933424305873\n",
      "reward : -767.3280432328447\n",
      "reward : -776.193134050737\n",
      "reward : -785.1414255477795\n",
      "reward : -794.1233471095378\n",
      "reward : -803.0886415165988\n",
      "reward : -811.9880012368162\n",
      "reward : -820.7746165767038\n",
      "reward : -829.4056167296039\n",
      "reward : -837.8433886329498\n",
      "reward : -846.0567554613204\n",
      "reward : -854.0219878425396\n",
      "reward : -861.7234526074739\n",
      "reward : -869.1552179242059\n",
      "reward : -876.3206634546245\n",
      "reward : -883.2311029214212\n",
      "reward : -889.9063939816899\n",
      "reward : -896.3742245395806\n",
      "reward : -902.6691345483666\n",
      "reward : -908.8313359464216\n",
      "reward : -914.9053945774011\n",
      "reward : -920.9388265485326\n",
      "reward : -926.9806431026382\n",
      "reward : -933.07986024739\n",
      "reward : -939.283979087095\n",
      "reward : -945.6374445360644\n",
      "reward : -952.180104684727\n",
      "reward : -958.9457173048779\n",
      "reward : -965.9605769839516\n",
      "reward : -973.2423572039334\n",
      "reward : -980.7992677201886\n",
      "reward : -988.6296136213186\n",
      "reward : -996.7218090565127\n",
      "reward : -1005.0548527306614\n",
      "reward : -1013.5992250337306\n",
      "reward : -1022.3181293564908\n",
      "reward : -1031.1689800003348\n",
      "reward : -1040.1050372354036\n",
      "reward : -1049.077102263101\n",
      "reward : -1058.0352042998238\n",
      "reward : -1066.9302323235925\n",
      "reward : -1075.7154808501762\n",
      "reward : -1084.3480901226474\n",
      "reward : -1092.790365318581\n",
      "reward : -1101.0109567227846\n",
      "reward : -1108.9858745022095\n",
      "reward : -1116.699209612187\n",
      "reward : -1124.144311830767\n",
      "reward : -1131.323671548352\n",
      "reward : -1138.248125501999\n",
      "reward : -1144.937053292226\n",
      "reward : -1151.4176811908783\n",
      "reward : -1157.7241195844595\n",
      "reward : -1163.896195766946\n",
      "reward : -1169.9781457414206\n",
      "reward : -1176.0172179800607\n",
      "reward : -1182.0622241251676\n",
      "reward : -1188.1620538031711\n",
      "reward : -1194.3641600645399\n",
      "reward : -1200.7130230651771\n",
      "reward : -1207.2486134796022\n",
      "reward : -1214.0049007679866\n",
      "reward : -1221.0084781838646\n",
      "reward : -1228.2773974822812\n",
      "reward : -1235.820313067736\n",
      "reward : -1243.6360224143764\n",
      "reward : -1251.7134572810103\n",
      "reward : -1260.0321351113478\n",
      "reward : -1268.5630329593941\n",
      "reward : -1277.2698085546474\n",
      "reward : -1286.1102721681596\n",
      "reward : -1295.0380101868166\n",
      "reward : -1304.0040727838477\n",
      "reward : -1312.9586571244204\n",
      "reward : -1321.8527377616142\n",
      "reward : -1330.6396128119027\n",
      "reward : -1339.276345760581\n",
      "reward : -1347.7250872963168\n",
      "reward : -1355.9542592874773\n",
      "reward : -1363.939575033779\n",
      "reward : -1371.6648042960562\n",
      "reward : -1379.1227196673842\n",
      "reward : -1386.3151416522016\n",
      "reward : -1393.2524624907862\n",
      "reward : -1399.9536257878065\n",
      "reward : -1406.4454461448163\n",
      "reward : -1412.76166035909\n",
      "reward : -1418.9417711563367\n",
      "reward : -1425.0297470626633\n",
      "reward : -1431.0726319172898\n",
      "reward : -1437.1190998860613\n",
      "reward : -1443.2179739826943\n",
      "reward : -1449.4167150631126\n",
      "reward : -1455.7598887578858\n",
      "reward : -1462.2876310382414\n",
      "reward : -1469.0341562599865\n",
      "reward : -1476.0263781558315\n",
      "reward : -2.1726300884320153\n",
      "reward : -4.568245401753447\n",
      "reward : -7.303357869848943\n",
      "reward : -10.504663510512133\n",
      "reward : -14.308606083239102\n",
      "reward : -18.8574348795812\n",
      "reward : -24.290920617314747\n",
      "reward : -30.733767522137924\n",
      "reward : -38.280325050311575\n",
      "reward : -46.98000766715447\n",
      "reward : -56.82779123304375\n",
      "reward : -67.76311670613363\n",
      "reward : -78.33519233354427\n",
      "reward : -87.6658470402458\n",
      "reward : -95.90517763962555\n",
      "reward : -103.25453357941419\n",
      "reward : -109.95396382002437\n",
      "reward : -116.26453420811852\n",
      "reward : -122.29329616632539\n",
      "reward : -128.09772025566312\n",
      "reward : -133.73467950707206\n",
      "reward : -139.26617153245002\n",
      "reward : -144.75749851604814\n",
      "reward : -150.27547616902885\n",
      "reward : -155.8866397764474\n",
      "reward : -161.65538946553676\n",
      "reward : -167.64202394664125\n",
      "reward : -173.9006528436218\n",
      "reward : -180.47704437680295\n",
      "reward : -187.40654101798378\n",
      "reward : -194.7122376927643\n",
      "reward : -202.40364126912044\n",
      "reward : -210.47600087493134\n",
      "reward : -218.9104175827074\n",
      "reward : -227.6747305669695\n",
      "reward : -236.72506897690832\n",
      "reward : -246.00788626843888\n",
      "reward : -255.46227208866082\n",
      "reward : -265.02236042479495\n",
      "reward : -274.61970177076665\n",
      "reward : -284.1855199538958\n",
      "reward : -293.65281733066007\n",
      "reward : -302.95832131741287\n",
      "reward : -312.0433842471877\n",
      "reward : -320.86062243274165\n",
      "reward : -329.38029456008786\n",
      "reward : -337.59151803959327\n",
      "reward : -345.4955086754129\n",
      "reward : -353.100293238563\n",
      "reward : -360.4181931257328\n",
      "reward : -367.46364623748724\n",
      "reward : -374.25390256213484\n",
      "reward : -380.81291550603186\n",
      "reward : -387.1723019817371\n",
      "reward : -393.37023407009815\n",
      "reward : -399.45015415117837\n",
      "reward : -405.4593774997223\n",
      "reward : -411.44762923403727\n",
      "reward : -417.4655411809265\n",
      "reward : -423.56311697427634\n",
      "reward : -429.7881672378817\n",
      "reward : -436.1847243666027\n",
      "reward : -442.7914673250411\n",
      "reward : -449.64021582873136\n",
      "reward : -456.7545816289805\n",
      "reward : -464.14888235648885\n",
      "reward : -471.8274221109416\n",
      "reward : -479.78421926234824\n",
      "reward : -488.0032192812567\n",
      "reward : -496.4589787850163\n",
      "reward : -505.1177593087593\n",
      "reward : -513.9389365974407\n",
      "reward : -522.8766186421601\n",
      "reward : -531.881371589765\n",
      "reward : -540.9019706291593\n",
      "reward : -549.887115355381\n",
      "reward : -558.7870698627412\n",
      "reward : -567.5552033622898\n",
      "reward : -576.1494158098086\n",
      "reward : -584.533434249769\n",
      "reward : -592.6779596395241\n",
      "reward : -600.5612983111629\n",
      "reward : -608.1720661192951\n",
      "reward : -615.5101488139113\n",
      "reward : -622.5830095335283\n",
      "reward : -629.4050883533965\n",
      "reward : -635.9992116429073\n",
      "reward : -642.3957734121342\n",
      "reward : -648.6316712281708\n",
      "reward : -654.7490624145009\n",
      "reward : -660.7940024804237\n",
      "reward : -666.8150127059317\n",
      "reward : -672.8616042460012\n",
      "reward : -678.9827697818661\n",
      "reward : -685.2254470722171\n",
      "reward : -691.6329651337578\n",
      "reward : -698.2435026312811\n",
      "reward : -705.0886147259059\n",
      "reward : -712.1919111769936\n",
      "reward : -719.56798555939\n",
      "reward : -727.221695079781\n",
      "reward : -735.1478691332039\n",
      "reward : -743.3314853284581\n",
      "reward : -751.7483031692252\n",
      "reward : -760.365899867926\n",
      "reward : -769.1450203978097\n",
      "reward : -778.0411401743978\n",
      "reward : -787.0061426866454\n",
      "reward : -795.9900303290141\n",
      "reward : -804.9426075115808\n",
      "reward : -813.8150949585277\n",
      "reward : -822.5616493216847\n",
      "reward : -831.1407710724171\n",
      "reward : -839.5165854213932\n",
      "reward : -847.6599760304325\n",
      "reward : -855.5494692134445\n",
      "reward : -863.1723285140105\n",
      "reward : -870.5255995589358\n",
      "reward : -877.6151777308306\n",
      "reward : -884.4549199505793\n",
      "reward : -891.0670416971886\n",
      "reward : -897.4813209533773\n",
      "reward : -903.7340551968775\n",
      "reward : -909.8668357936618\n",
      "reward : -915.9252013176202\n",
      "reward : -921.9572172187476\n",
      "reward : -928.0120103067529\n",
      "reward : -934.1382702994689\n",
      "reward : -940.3827236176537\n",
      "reward : -946.7885901912113\n",
      "reward : -953.3940519186815\n",
      "reward : -960.2307872229487\n",
      "reward : -967.3226522306014\n",
      "reward : -974.6846063363107\n",
      "reward : -982.32198038833\n",
      "reward : -990.2301657454882\n",
      "reward : -998.394764514366\n",
      "reward : -1006.792193851556\n",
      "reward : -1015.3906919268111\n",
      "reward : -1024.1516404227198\n",
      "reward : -1033.0311038299947\n",
      "reward : -1041.9814886438078\n",
      "reward : -1050.9532405755672\n",
      "reward : -1059.896518140772\n",
      "reward : -1068.7628005895483\n",
      "reward : -1077.5064034080435\n",
      "reward : -1086.0858836939715\n",
      "reward : -1094.4653198822607\n",
      "reward : -1102.6154457984783\n",
      "reward : -1110.5146095948412\n",
      "reward : -1118.14943606902\n",
      "reward : -1125.515853243633\n",
      "reward : -1132.618936026935\n",
      "reward : -1139.4720795895742\n",
      "reward : -1146.0970438021448\n",
      "reward : -1152.5231735257114\n",
      "reward : -1158.7863697566\n",
      "reward : -1164.927875316541\n",
      "reward : -1170.9929366700737\n",
      "reward : -1177.0293899399703\n",
      "reward : -1183.086200512398\n",
      "reward : -1189.2119692966355\n",
      "reward : -1195.4534111863595\n",
      "reward : -1201.8538161974434\n",
      "reward : -1208.4515209660449\n",
      "reward : -1215.2784436249644\n",
      "reward : -1222.3587610811649\n",
      "reward : -1229.7078253568077\n",
      "reward : -1237.3314169737575\n",
      "reward : -1245.225414443931\n",
      "reward : -1253.3759219554988\n",
      "reward : -1261.7598504763414\n",
      "reward : -1270.3459021791973\n",
      "reward : -1279.095874815243\n",
      "reward : -1287.9661871989624\n",
      "reward : -1296.9095289765992\n",
      "reward : -1305.876552256425\n",
      "reward : -1314.817542634629\n",
      "reward : -1323.684026735379\n",
      "reward : -1332.430288804694\n",
      "reward : -1341.0147782419265\n",
      "reward : -1349.4013924609512\n",
      "reward : -1357.5606153282959\n",
      "reward : -1365.4704822824638\n",
      "reward : -1373.1172827294372\n",
      "reward : -1380.496389311206\n",
      "reward : -1387.6122411003198\n",
      "reward : -1394.4777995154461\n",
      "reward : -1401.1144048766307\n",
      "reward : -1407.5510116151627\n",
      "reward : -1413.8231719917442\n",
      "reward : -1419.9718314963518\n",
      "reward : -1426.0419976696182\n",
      "reward : -1432.0813310957053\n",
      "reward : -1438.138688844499\n",
      "reward : -1444.2626341583161\n",
      "reward : -1450.4999182014344\n",
      "reward : -1456.8939439960309\n",
      "reward : -1463.4832392772742\n",
      "reward : -1470.2999899546035\n"
     ]
    }
   ],
   "source": [
    "model.test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(self.env.single_observation_space.shape[0],self.env.single_action_space.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"runs/PPO_version0__{int(time.time())}\")\n",
    "for i in range(6):   \n",
    "    writer.add_scalar('test',i*5,global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,info=envs.step(envs.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.reset()\n",
    "action=envs.action_space.sample()\n",
    "\n",
    "a,r,_,_,_=envs.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39mtensor(r)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "torch.tensor(r).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.79173457, -8.0906354 , -0.00858438, -1.92236239])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(envs.single_observation_space.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(envs.single_action_space.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncVectorEnv(4)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward : -5.683198897724099\n",
      "reward : -11.208939319031344\n",
      "reward : -16.775036598660108\n",
      "reward : -22.602178717270895\n",
      "reward : -28.92496160219052\n",
      "reward : -35.97766688355183\n",
      "reward : -43.97362665114854\n",
      "reward : -53.08937617572663\n",
      "reward : -63.44965861216113\n",
      "reward : -74.21500973868085\n",
      "reward : -83.92743732916831\n",
      "reward : -92.56446406350878\n",
      "reward : -100.14580845864471\n",
      "reward : -106.73886257060795\n",
      "reward : -112.45662330285907\n",
      "reward : -117.44923092596498\n",
      "reward : -121.89401106947278\n",
      "reward : -125.98452627156624\n",
      "reward : -129.92013617933108\n",
      "reward : -133.90201972758118\n",
      "reward : -138.13371340125065\n",
      "reward : -142.82158102885188\n",
      "reward : -148.17749349262945\n",
      "reward : -154.41592448927324\n",
      "reward : -161.7440337743586\n",
      "reward : -170.34196655240683\n",
      "reward : -180.34314324381728\n",
      "reward : -191.8178053249521\n",
      "reward : -202.45591257257533\n",
      "reward : -211.81543352545953\n",
      "reward : -219.91888461981281\n",
      "reward : -226.83907314373178\n",
      "reward : -232.6979051976398\n",
      "reward : -237.65808762311315\n",
      "reward : -241.91197298695064\n",
      "reward : -245.67091596542298\n",
      "reward : -249.15924382105516\n",
      "reward : -252.61611148249818\n",
      "reward : -256.30562216620973\n",
      "reward : -260.52151542862634\n",
      "reward : -265.5808762545431\n",
      "reward : -271.8029657215966\n",
      "reward : -279.4902403606273\n",
      "reward : -288.8933887925026\n",
      "reward : -300.1792102974391\n",
      "reward : -312.4156131715177\n",
      "reward : -323.1408006203275\n",
      "reward : -332.3051490630778\n",
      "reward : -339.9325426206087\n",
      "reward : -346.12834010277356\n",
      "reward : -351.06804528274137\n",
      "reward : -354.97520062210515\n",
      "reward : -358.0947575252517\n",
      "reward : -360.6721111494394\n",
      "reward : -362.93945841461846\n",
      "reward : -365.1129716533914\n",
      "reward : -367.3965704163327\n",
      "reward : -369.99408219700916\n",
      "reward : -373.12579394047805\n",
      "reward : -377.03881957731056\n",
      "reward : -382.0047873297692\n",
      "reward : -388.3132767296926\n",
      "reward : -396.2462597725147\n",
      "reward : -406.0445053645138\n",
      "reward : -417.8673146676975\n",
      "reward : -430.61545094852\n",
      "reward : -441.6794535787713\n",
      "reward : -451.0350300982781\n",
      "reward : -458.7307417061336\n",
      "reward : -464.8948562327525\n",
      "reward : -469.7199649947442\n",
      "reward : -473.43610417666014\n",
      "reward : -476.2842679519222\n",
      "reward : -478.4973685091864\n",
      "reward : -480.29273544666887\n",
      "reward : -481.8743700640033\n",
      "reward : -483.44130435679426\n",
      "reward : -485.2056007697005\n",
      "reward : -487.4070213414901\n",
      "reward : -490.3291097054311\n",
      "reward : -494.3014853383077\n",
      "reward : -499.69619669107334\n",
      "reward : -506.90753308778426\n",
      "reward : -516.3058799224262\n",
      "reward : -528.1691717445223\n",
      "reward : -542.6196381886366\n",
      "reward : -555.5513644681334\n",
      "reward : -566.4555082406476\n",
      "reward : -575.3165672497825\n",
      "reward : -582.2490183510538\n",
      "reward : -587.4827946305717\n",
      "reward : -591.3145019940926\n",
      "reward : -594.0541288896744\n",
      "reward : -595.9860059097874\n",
      "reward : -597.348022570348\n",
      "reward : -598.330206298656\n",
      "reward : -599.0806349009149\n",
      "reward : -599.7160322180689\n",
      "reward : -600.3318040136542\n",
      "reward : -601.0143958197939\n",
      "reward : -601.8542318095093\n",
      "reward : -602.9581100565264\n",
      "reward : -604.4629813201221\n",
      "reward : -606.5463189993746\n",
      "reward : -609.4372681092275\n",
      "reward : -613.4224728730492\n",
      "reward : -618.8443002504911\n",
      "reward : -626.0828764766645\n",
      "reward : -635.508206995529\n",
      "reward : -647.4145410585587\n",
      "reward : -661.9567664159033\n",
      "reward : -675.5137051699982\n",
      "reward : -686.986513677059\n",
      "reward : -696.3699673816817\n",
      "reward : -703.7795706713489\n",
      "reward : -709.4413163212337\n",
      "reward : -713.6432305448596\n",
      "reward : -716.6863554644779\n",
      "reward : -718.845384384399\n",
      "reward : -720.3511247511632\n",
      "reward : -721.3856769859302\n",
      "reward : -722.0870466085674\n",
      "reward : -722.5559469627531\n",
      "reward : -722.8652956047923\n",
      "reward : -723.0666001594127\n",
      "reward : -723.1955633284481\n",
      "reward : -723.2769920848539\n",
      "reward : -723.3285781876496\n",
      "reward : -723.3634417181635\n",
      "reward : -723.3919254409429\n",
      "reward : -723.4229907160781\n",
      "reward : -723.4656087661347\n",
      "reward : -723.5303161835476\n",
      "reward : -723.6310482187865\n",
      "reward : -723.7874814855151\n",
      "reward : -724.0279385622223\n",
      "reward : -724.3934983262684\n",
      "reward : -724.9436882183311\n",
      "reward : -725.763842064015\n",
      "reward : -726.9762604410613\n",
      "reward : -728.753893023081\n",
      "reward : -731.3386311021223\n",
      "reward : -735.0574760425887\n",
      "reward : -740.3275417874654\n",
      "reward : -747.6355133330736\n",
      "reward : -757.4788007946543\n",
      "reward : -770.2631147650751\n",
      "reward : -785.7369192251133\n",
      "reward : -800.3800500842292\n",
      "reward : -812.7427179324649\n",
      "reward : -822.7673301424337\n",
      "reward : -830.5634870283064\n",
      "reward : -836.3972552477863\n",
      "reward : -840.6240133708775\n",
      "reward : -843.6125837280886\n",
      "reward : -845.6934230893589\n",
      "reward : -847.1312475341778\n",
      "reward : -848.1263954158245\n",
      "reward : -848.8251174735427\n",
      "reward : -849.3320676681259\n",
      "reward : -849.7219822105687\n",
      "reward : -850.0502308605272\n",
      "reward : -850.3615068568341\n",
      "reward : -850.6973068820469\n",
      "reward : -851.1026149707594\n",
      "reward : -851.6327383978164\n",
      "reward : -852.3615089248055\n",
      "reward : -853.3913530781795\n",
      "reward : -854.8665444566744\n",
      "reward : -856.9903285181119\n",
      "reward : -860.0429728126138\n",
      "reward : -864.3977445659359\n",
      "reward : -870.5172631774758\n",
      "reward : -878.9190435058557\n",
      "reward : -890.0959922764547\n",
      "reward : -904.1372406375509\n",
      "reward : -920.266214366491\n",
      "reward : -934.0596840854055\n",
      "reward : -945.5320629117501\n",
      "reward : -954.68765166688\n",
      "reward : -961.6997066131064\n",
      "reward : -966.8782271455071\n",
      "reward : -970.591567510204\n",
      "reward : -973.1996136802546\n",
      "reward : -975.0088385334915\n",
      "reward : -976.258355799899\n",
      "reward : -977.126961289077\n",
      "reward : -977.7435015858699\n",
      "reward : -978.2000302074757\n",
      "reward : -978.5629587305652\n",
      "reward : -978.8829135607048\n",
      "reward : -979.2028867119296\n",
      "reward : -979.5655801847411\n",
      "reward : -980.0198651536354\n",
      "reward : -980.6283270137455\n",
      "reward : -981.4759788707704\n",
      "reward : -982.6820813917931\n",
      "reward : -984.4145576583944\n",
      "reward : -986.9082244866806\n",
      "reward : -990.4835040751814\n",
      "reward : -1.6429137518160553\n",
      "reward : -3.21816499419995\n",
      "reward : -4.934505576110723\n",
      "reward : -7.024771038831199\n",
      "reward : -9.761522976106821\n",
      "reward : -13.464097756450435\n",
      "reward : -18.495129488607162\n",
      "reward : -25.245889660842096\n",
      "reward : -34.09635557099209\n",
      "reward : -45.35077884096683\n",
      "reward : -59.17137517491815\n",
      "reward : -72.5329455851616\n",
      "reward : -83.89353102664691\n",
      "reward : -93.2098312353482\n",
      "reward : -100.56575606827911\n",
      "reward : -106.16644425591909\n",
      "reward : -110.29682882753788\n",
      "reward : -113.26633816713324\n",
      "reward : -115.36769014125919\n",
      "reward : -116.84976161673751\n",
      "reward : -117.9140106640902\n",
      "reward : -118.71815379919384\n",
      "reward : -119.38632009415872\n",
      "reward : -120.01950037661638\n",
      "reward : -120.70723963312207\n",
      "reward : -121.541197690691\n",
      "reward : -122.62742759219572\n",
      "reward : -124.10087410404547\n",
      "reward : -126.13568030869777\n",
      "reward : -128.95658243345514\n",
      "reward : -132.8452659770808\n",
      "reward : -138.1392108719035\n",
      "reward : -145.2155499496841\n",
      "reward : -154.44588456774042\n",
      "reward : -166.13164767849563\n",
      "reward : -180.439630789047\n",
      "reward : -194.13439454575663\n",
      "reward : -205.75446695709505\n",
      "reward : -215.28647060812145\n",
      "reward : -222.83558172257804\n",
      "reward : -228.61944725217637\n",
      "reward : -232.92198612138853\n",
      "reward : -236.0437659705528\n",
      "reward : -238.26168696209086\n",
      "reward : -239.8097665384771\n",
      "reward : -240.87369172585414\n",
      "reward : -241.59467314868257\n",
      "reward : -242.07622021462583\n",
      "reward : -242.39342274229597\n",
      "reward : -242.59967755069118\n",
      "reward : -242.73230285109935\n",
      "reward : -242.81765477780075\n",
      "reward : -242.87512417163586\n",
      "reward : -242.91984018796947\n",
      "reward : -242.96459362245275\n",
      "reward : -243.02168321876007\n",
      "reward : -243.104973119616\n",
      "reward : -243.23234264149434\n",
      "reward : -243.42875028340342\n",
      "reward : -243.72953039234878\n",
      "reward : -244.185717927656\n",
      "reward : -244.87045993482448\n",
      "reward : -245.88822913707529\n",
      "reward : -247.38774623376855\n",
      "reward : -249.57766534516406\n",
      "reward : -252.74537798276154\n",
      "reward : -257.26844143527074\n",
      "reward : -263.6063776927352\n",
      "reward : -272.2602549379629\n",
      "reward : -283.6900644485671\n",
      "reward : -298.1494386198184\n",
      "reward : -313.81837876056835\n",
      "reward : -327.21152210161233\n",
      "reward : -338.2660103852367\n",
      "reward : -347.0174404261881\n",
      "reward : -353.6704549681987\n",
      "reward : -358.5535965228122\n",
      "reward : -362.03915239938766\n",
      "reward : -364.48114005410804\n",
      "reward : -366.1744015306506\n",
      "reward : -367.34646108476613\n",
      "reward : -368.16642637284053\n",
      "reward : -368.7558836127422\n",
      "reward : -369.20208620863366\n",
      "reward : -369.5690706251894\n",
      "reward : -369.9073450602861\n",
      "reward : -370.2621238731506\n",
      "reward : -370.6807852142508\n",
      "reward : -371.22016289335966\n",
      "reward : -371.9548939651303\n",
      "reward : -372.9877988574244\n",
      "reward : -374.4631986717771\n",
      "reward : -376.58421569544976\n",
      "reward : -379.6307935652689\n",
      "reward : -383.9760045905185\n",
      "reward : -390.0826921237646\n",
      "reward : -398.4694135848122\n",
      "reward : -409.6311667594798\n",
      "reward : -423.6459919126087\n",
      "reward : -439.8048348311769\n",
      "reward : -453.6243465669466\n",
      "reward : -465.1239634460769\n",
      "reward : -474.30600887425277\n",
      "reward : -481.3416938957939\n",
      "reward : -486.53976175772215\n",
      "reward : -490.26826459314043\n",
      "reward : -492.88743561852\n",
      "reward : -494.7044994535117\n",
      "reward : -495.95934187249776\n",
      "reward : -496.8313959386138\n",
      "reward : -497.4500071550393\n",
      "reward : -497.9075733826326\n",
      "reward : -498.27070437712007\n",
      "reward : -498.5900957714998\n",
      "reward : -498.9086844205053\n",
      "reward : -499.26898279221757\n",
      "reward : -499.7195256411744\n",
      "reward : -500.3223570536743\n",
      "reward : -501.16170669262567\n",
      "reward : -502.3556863096183\n",
      "reward : -504.07057625999954\n",
      "reward : -506.5390616017948\n",
      "reward : -510.07898265249105\n",
      "reward : -515.1022808615863\n",
      "reward : -522.101001103462\n",
      "reward : -531.5949644265386\n",
      "reward : -544.0327444839711\n",
      "reward : -559.0102810868909\n",
      "reward : -574.1401532017359\n",
      "reward : -587.0134426653426\n",
      "reward : -597.5417248847741\n",
      "reward : -605.7990277824993\n",
      "reward : -612.0239117006716\n",
      "reward : -616.5614307996025\n",
      "reward : -619.7837568785815\n",
      "reward : -622.0343470740822\n",
      "reward : -623.592787274807\n",
      "reward : -624.6725284320574\n",
      "reward : -625.430780653405\n",
      "reward : -625.9803310387078\n",
      "reward : -626.4021673958478\n",
      "reward : -626.756352699475\n",
      "reward : -627.0912606709102\n",
      "reward : -627.451537989314\n",
      "reward : -627.8853961783142\n",
      "reward : -628.452002741376\n",
      "reward : -629.229986776459\n",
      "reward : -630.3284127697756\n",
      "reward : -631.9003843963991\n",
      "reward : -634.1609455327851\n",
      "reward : -637.4058636720135\n",
      "reward : -642.0247728029442\n",
      "reward : -648.4938705213153\n",
      "reward : -657.3343470599482\n",
      "reward : -669.0251033307952\n",
      "reward : -683.4295192129484\n",
      "reward : -699.1576040005699\n",
      "reward : -712.6021336711316\n",
      "reward : -723.710177396787\n",
      "reward : -732.5132110459747\n",
      "reward : -739.2118585501673\n",
      "reward : -744.1323655391654\n",
      "reward : -747.6465962062464\n",
      "reward : -750.1093687290952\n",
      "reward : -751.8170247932659\n",
      "reward : -752.9985480393525\n",
      "reward : -753.8242736531956\n",
      "reward : -754.4166738202587\n",
      "reward : -754.8635616988782\n",
      "reward : -755.229197133251\n",
      "reward : -755.563992489525\n",
      "reward : -755.9127237034456\n",
      "reward : -756.3219603747508\n",
      "reward : -756.8471812423579\n",
      "reward : -757.5610462328232\n",
      "reward : -758.5634350434099\n",
      "reward : -759.9946069061824\n",
      "reward : -762.0521365661181\n",
      "reward : -765.008785605345\n",
      "reward : -769.2295892952101\n",
      "reward : -775.1705689590327\n",
      "reward : -783.3479031391246\n",
      "reward : -794.2625367226028\n",
      "reward : -808.1009632016749\n",
      "reward : -824.2809734186599\n",
      "reward : -838.2766965563239\n",
      "reward : -849.9607247965512\n",
      "reward : -859.3218651496313\n",
      "reward : -866.5179600686548\n",
      "reward : -871.8490831801312\n",
      "reward : -875.6810954529209\n",
      "reward : -878.3764111347723\n",
      "reward : -880.2473045666275\n",
      "reward : -881.5389005204959\n",
      "reward : -882.4349797672346\n",
      "reward : -883.0683253181854\n",
      "reward : -883.5337390376476\n",
      "reward : -883.8992691219272\n",
      "reward : -884.2162091799306\n",
      "reward : -884.5273047045148\n",
      "reward : -4.095750156943591\n",
      "reward : -8.228763305973835\n",
      "reward : -12.598684618205938\n",
      "reward : -17.40755073610728\n",
      "reward : -22.86159055368796\n",
      "reward : -29.168324895314367\n",
      "reward : -36.5273313311184\n",
      "reward : -45.11266094409347\n",
      "reward : -55.05251052415872\n",
      "reward : -66.41482864268642\n",
      "reward : -76.97515235654727\n",
      "reward : -86.2951577926093\n",
      "reward : -94.39783293530667\n",
      "reward : -101.35436615968023\n",
      "reward : -107.28326630915353\n",
      "reward : -112.34281631114106\n",
      "reward : -116.72102153819792\n",
      "reward : -120.62582569144318\n",
      "reward : -124.27940169877786\n",
      "reward : -127.92068748839665\n",
      "reward : -131.81456674827137\n",
      "reward : -136.25478642786294\n",
      "reward : -141.55502686832267\n",
      "reward : -148.02671625471152\n",
      "reward : -155.9592464614326\n",
      "reward : -165.58570784548476\n",
      "reward : -177.053564413936\n",
      "reward : -188.91906374280416\n",
      "reward : -199.30289476167462\n",
      "reward : -208.16778238366987\n",
      "reward : -215.54923565458117\n",
      "reward : -221.56024237914858\n",
      "reward : -226.37901316214095\n",
      "reward : -230.22740704455936\n",
      "reward : -233.34670486089462\n",
      "reward : -235.9781111977915\n",
      "reward : -238.35128386726944\n",
      "reward : -240.68192491391133\n",
      "reward : -243.1766215859571\n",
      "reward : -246.04579675583\n",
      "reward : -249.5188446592169\n",
      "reward : -253.85026821867575\n",
      "reward : -259.31368529105544\n",
      "reward : -266.19306948511235\n",
      "reward : -274.7508150405346\n",
      "reward : -285.1954675631503\n",
      "reward : -297.6443059783612\n",
      "reward : -309.65017556295845\n",
      "reward : -319.9915553337864\n",
      "reward : -328.67029680906234\n",
      "reward : -335.7630565679385\n",
      "reward : -341.42029434658593\n",
      "reward : -345.8463569927266\n",
      "reward : -349.2735357175763\n",
      "reward : -351.93909486478833\n",
      "reward : -354.0710076600357\n",
      "reward : -355.8848638590014\n",
      "reward : -357.5886839188781\n",
      "reward : -359.3965505743586\n",
      "reward : -361.5452333379501\n",
      "reward : -364.308353971354\n",
      "reward : -368.0047508160605\n",
      "reward : -372.99318560823974\n",
      "reward : -379.6584684521823\n",
      "reward : -388.3739790090805\n",
      "reward : -399.44072061166645\n",
      "reward : -413.0234275592794\n",
      "reward : -426.31242653930934\n",
      "reward : -437.6375998383327\n",
      "reward : -446.95329614190035\n",
      "reward : -454.3363782057006\n",
      "reward : -459.9819016410592\n",
      "reward : -464.16553877821724\n",
      "reward : -467.1904233998764\n",
      "reward : -469.3470128030582\n",
      "reward : -470.885304333869\n",
      "reward : -472.01031711692474\n",
      "reward : -472.8854191596566\n",
      "reward : -473.6420476222568\n",
      "reward : -474.3900383241941\n",
      "reward : -475.23093877867495\n",
      "reward : -476.27262402701035\n",
      "reward : -477.643528348756\n",
      "reward : -479.5067324724597\n",
      "reward : -482.0705679620768\n",
      "reward : -485.59686917450193\n",
      "reward : -490.4020487242805\n",
      "reward : -496.847827985262\n",
      "reward : -505.30655679156644\n",
      "reward : -516.1021743068601\n",
      "reward : -529.4448888349979\n",
      "reward : -543.6546749566568\n",
      "reward : -555.8376694049293\n",
      "reward : -565.9523422700954\n",
      "reward : -574.062428517316\n",
      "reward : -580.3484068882473\n",
      "reward : -585.0729029156439\n",
      "reward : -588.529853061582\n",
      "reward : -591.0025428800327\n",
      "reward : -592.7365473581115\n",
      "reward : -593.9319732283748\n",
      "reward : -594.7435694618301\n",
      "reward : -595.2874634807148\n",
      "reward : -595.6493357227389\n",
      "reward : -595.8925803741022\n",
      "reward : -596.0641829232901\n",
      "reward : -596.2012001452651\n",
      "reward : -596.335563424912\n",
      "reward : -596.4982663855285\n",
      "reward : -596.7244356024557\n",
      "reward : -597.0592943019099\n",
      "reward : -597.5637162177616\n",
      "reward : -598.3225155459403\n",
      "reward : -599.4540608539609\n",
      "reward : -601.1238432656884\n",
      "reward : -603.5622585783807\n",
      "reward : -607.0811124713814\n",
      "reward : -612.0807516959868\n",
      "reward : -619.0332202150694\n",
      "reward : -628.4300471063733\n",
      "reward : -640.6877695489501\n",
      "reward : -655.8744550361661\n",
      "reward : -670.7958159548228\n",
      "reward : -683.4503732279956\n",
      "reward : -693.7624731512718\n",
      "reward : -701.8212799706895\n",
      "reward : -707.8773204212403\n",
      "reward : -712.2803246777313\n",
      "reward : -715.4010771418156\n",
      "reward : -717.5776831614656\n",
      "reward : -719.0833345696558\n",
      "reward : -720.125792547617\n",
      "reward : -720.8575032536559\n",
      "reward : -721.3876746930771\n",
      "reward : -721.794490571977\n",
      "reward : -722.1358509784557\n",
      "reward : -722.4583408750101\n",
      "reward : -722.8049505512413\n",
      "reward : -723.2220766165447\n",
      "reward : -723.7665995550982\n",
      "reward : -724.5142077793271\n",
      "reward : -725.5698383343164\n",
      "reward : -727.0810610598609\n",
      "reward : -729.2555411662622\n",
      "reward : -732.3792828866307\n",
      "reward : -736.8317726001144\n",
      "reward : -743.0809081820312\n",
      "reward : -751.6459691412507\n",
      "reward : -763.0151577992945\n",
      "reward : -777.1900964253566\n",
      "reward : -793.169424684596\n",
      "reward : -806.8325125461546\n",
      "reward : -818.16860066202\n",
      "reward : -827.1920140843747\n",
      "reward : -834.0862453509557\n",
      "reward : -839.1674925334133\n",
      "reward : -842.8055494215009\n",
      "reward : -845.358482981439\n",
      "reward : -847.1289928818209\n",
      "reward : -848.3523456709328\n",
      "reward : -849.2041747153746\n",
      "reward : -849.8108736525306\n",
      "reward : -850.2628258323365\n",
      "reward : -850.6255230783696\n",
      "reward : -850.9493432089585\n",
      "reward : -851.2777056212706\n",
      "reward : -851.6544551710724\n",
      "reward : -852.130428207909\n",
      "reward : -852.7713376024907\n",
      "reward : -853.6666902553399\n",
      "reward : -854.9423120767465\n",
      "reward : -856.775480284231\n",
      "reward : -859.4130570358534\n",
      "reward : -863.189911063884\n",
      "reward : -868.534620923018\n",
      "reward : -875.9498232100406\n",
      "reward : -885.9515838034465\n",
      "reward : -898.9620549053109\n",
      "reward : -914.3768845197183\n",
      "reward : -929.0764262167423\n",
      "reward : -941.4982714325213\n",
      "reward : -951.5810723587806\n",
      "reward : -959.430266701671\n",
      "reward : -965.3088119973776\n",
      "reward : -969.5709965052138\n",
      "reward : -972.5860795830397\n",
      "reward : -974.6860783189638\n",
      "reward : -976.1374252072208\n",
      "reward : -977.1419388055323\n",
      "reward : -977.8471247150716\n",
      "reward : -978.3585396115313\n",
      "reward : -978.751592651818\n",
      "reward : -979.0821323439582\n",
      "reward : -979.3951890204273\n",
      "reward : -979.7324967668702\n",
      "reward : -980.13923342534\n",
      "reward : -980.6708882086804\n",
      "reward : -981.4014780148659\n",
      "reward : -982.4336597358783\n",
      "reward : -983.9119952416387\n",
      "reward : -9.396295134447614\n",
      "reward : -18.801439501360576\n",
      "reward : -28.26507195455148\n",
      "reward : -37.8369208664505\n",
      "reward : -47.56497843752581\n",
      "reward : -57.4480337523992\n",
      "reward : -67.12497037947367\n",
      "reward : -76.57004373764593\n",
      "reward : -85.76486506437203\n",
      "reward : -94.69941145523788\n",
      "reward : -103.37285482343515\n",
      "reward : -111.7941114105417\n",
      "reward : -119.98195761336774\n",
      "reward : -127.96470966865927\n",
      "reward : -135.77949436442063\n",
      "reward : -143.47130320720575\n",
      "reward : -151.0917441731252\n",
      "reward : -158.69763287381502\n",
      "reward : -166.34931135999676\n",
      "reward : -174.1083612828003\n",
      "reward : -182.03479803037104\n",
      "reward : -190.1850052076767\n",
      "reward : -198.60931467394653\n",
      "reward : -207.34975710635186\n",
      "reward : -216.43867262541457\n",
      "reward : -225.89674354759413\n",
      "reward : -235.7315794949572\n",
      "reward : -245.54964824337694\n",
      "reward : -255.00590225823817\n",
      "reward : -264.1278038051923\n",
      "reward : -272.95665576598816\n",
      "reward : -281.54736897586145\n",
      "reward : -289.96749468474826\n",
      "reward : -298.29565257686045\n",
      "reward : -306.6201020758391\n",
      "reward : -315.036360856727\n",
      "reward : -323.64269622141614\n",
      "reward : -332.53591304001606\n",
      "reward : -341.80631640351095\n",
      "reward : -351.53217816137743\n",
      "reward : -361.47727463499626\n",
      "reward : -370.96405439552035\n",
      "reward : -379.9705387736661\n",
      "reward : -388.49173007670794\n",
      "reward : -396.5407342332135\n",
      "reward : -404.1493260821956\n",
      "reward : -411.3673716954569\n",
      "reward : -418.26125845565747\n",
      "reward : -424.9118638090521\n",
      "reward : -431.4118683777286\n",
      "reward : -437.86290255070395\n",
      "reward : -444.37313259454874\n",
      "reward : -451.0538846302756\n",
      "reward : -458.0161997132469\n",
      "reward : -465.3663688624697\n",
      "reward : -473.2019378409714\n",
      "reward : -481.60901778314775\n",
      "reward : -490.65673380218504\n",
      "reward : -500.3920046324037\n",
      "reward : -510.63485176342476\n",
      "reward : -520.2099419621369\n",
      "reward : -529.129283989822\n",
      "reward : -537.4278193963038\n",
      "reward : -545.1641543695711\n",
      "reward : -552.420172357645\n",
      "reward : -559.3006000085762\n",
      "reward : -565.9313417102018\n",
      "reward : -572.4580727967461\n",
      "reward : -579.045467943008\n",
      "reward : -585.8734289711565\n",
      "reward : -593.1290735790527\n",
      "reward : -600.9948514928695\n",
      "reward : -609.631717878594\n",
      "reward : -619.1693709396993\n",
      "reward : -629.6950411783342\n",
      "reward : -639.6375540044088\n",
      "reward : -648.7294577364233\n",
      "reward : -656.9667315455456\n",
      "reward : -664.3797104813469\n",
      "reward : -671.0335222054291\n",
      "reward : -677.0271291503263\n",
      "reward : -682.4879596687057\n",
      "reward : -687.564139005507\n",
      "reward : -692.417274027671\n",
      "reward : -697.2171133182189\n",
      "reward : -702.138782166583\n",
      "reward : -707.361394446771\n",
      "reward : -713.0647976579346\n",
      "reward : -719.4269266247285\n",
      "reward : -726.6191079349898\n",
      "reward : -734.79492213402\n",
      "reward : -744.0759653067087\n",
      "reward : -754.5391598534846\n",
      "reward : -765.189603252167\n",
      "reward : -774.7724951257743\n",
      "reward : -783.2982875451835\n",
      "reward : -790.8164655665378\n",
      "reward : -797.4164073332144\n",
      "reward : -803.2247109428977\n",
      "reward : -808.3990843806517\n",
      "reward : -813.1216337833994\n",
      "reward : -817.5944090666636\n",
      "reward : -822.0398538416904\n",
      "reward : -826.706343030111\n",
      "reward : -831.8668432215774\n",
      "reward : -837.8068250455268\n",
      "reward : -844.8013292675312\n",
      "reward : -853.0951739580586\n",
      "reward : -862.8783516831693\n",
      "reward : -874.2638821388717\n",
      "reward : -885.2302869629054\n",
      "reward : -894.889425726866\n",
      "reward : -903.2264314603176\n",
      "reward : -910.2879176374862\n",
      "reward : -916.1834347706854\n",
      "reward : -921.0751048974028\n",
      "reward : -925.1626224483233\n",
      "reward : -928.6660166185312\n",
      "reward : -931.8109669351365\n",
      "reward : -934.8188006229069\n",
      "reward : -937.9049896134491\n",
      "reward : -941.2841880312583\n",
      "reward : -945.1798160996508\n",
      "reward : -949.8308488468282\n",
      "reward : -955.4881138626749\n",
      "reward : -962.4035066499201\n",
      "reward : -970.804718388932\n",
      "reward : -980.8714978940342\n",
      "reward : -992.7071094729553\n",
      "reward : -1004.1975179118596\n",
      "reward : -1014.1886743936825\n",
      "reward : -1022.6870866722344\n",
      "reward : -1029.7622682142257\n",
      "reward : -1035.545988558562\n",
      "reward : -1040.219561719187\n",
      "reward : -1043.9956367760537\n",
      "reward : -1047.1006825062943\n",
      "reward : -1049.763903963929\n",
      "reward : -1052.2148943168143\n",
      "reward : -1054.690807071362\n",
      "reward : -1057.4523792952023\n",
      "reward : -1060.7921121078089\n",
      "reward : -1065.0386835472193\n",
      "reward : -1070.541563933725\n",
      "reward : -1077.6536488580878\n",
      "reward : -1086.6944413475428\n",
      "reward : -1097.900662203446\n",
      "reward : -1111.3809149956533\n",
      "reward : -1123.4494997029226\n",
      "reward : -1133.718122047238\n",
      "reward : -1142.1772452256648\n",
      "reward : -1148.9216023204485\n",
      "reward : -1154.140399844201\n",
      "reward : -1158.0857631362376\n",
      "reward : -1161.032739717849\n",
      "reward : -1163.2484085934532\n",
      "reward : -1164.972286191677\n",
      "reward : -1166.4122422188925\n",
      "reward : -1167.7491048279264\n",
      "reward : -1169.1450193508374\n",
      "reward : -1170.7592208328717\n",
      "reward : -1172.7665881297385\n",
      "reward : -1175.3745532332036\n",
      "reward : -1178.8307385336434\n",
      "reward : -1183.424514952137\n",
      "reward : -1189.4808754518153\n",
      "reward : -1197.3338183235949\n",
      "reward : -1207.2812087586497\n",
      "reward : -1219.5303732702287\n",
      "reward : -1233.4010369545163\n",
      "reward : -1245.4005018769506\n",
      "reward : -1255.4826298850876\n",
      "reward : -1263.6861251986074\n",
      "reward : -1270.149370825229\n",
      "reward : -1275.0918037200295\n",
      "reward : -1278.7748061830664\n",
      "reward : -1281.4626456898657\n",
      "reward : -1283.3972646980353\n",
      "reward : -1284.7872688116884\n",
      "reward : -1285.8074419032446\n",
      "reward : -1286.6044952046454\n",
      "reward : -1287.3071651644689\n",
      "reward : -1288.0367726749391\n",
      "reward : -1288.9224281071663\n",
      "reward : -1290.115634034871\n",
      "reward : -1291.8055132811587\n",
      "reward : -1294.232469833273\n",
      "reward : -1297.7023366832468\n",
      "reward : -1302.5947340252485\n",
      "reward : -1309.344526940019\n",
      "reward : -1318.3954608731983\n",
      "reward : -1330.119524237448\n",
      "reward : -1344.7226255730031\n",
      "reward : -1359.3232180822274\n",
      "reward : -1371.7060515495868\n",
      "reward : -1381.8027191397555\n",
      "reward : -1389.7019865268053\n",
      "reward : -1395.6454096723428\n",
      "reward : -1399.969214114219\n",
      "reward : -1403.0306038947097\n",
      "reward : -7.722453819319502\n",
      "reward : -15.327127670344012\n",
      "reward : -22.869456522707086\n",
      "reward : -30.40999215230925\n",
      "reward : -38.012533056653176\n",
      "reward : -45.74152849552998\n",
      "reward : -53.65934548834268\n",
      "reward : -61.8240537429338\n",
      "reward : -70.28673165995365\n",
      "reward : -79.08969849195535\n",
      "reward : -88.26466161831472\n",
      "reward : -97.83080315285115\n",
      "reward : -107.79319560737233\n",
      "reward : -117.4959209550191\n",
      "reward : -126.82365399530572\n",
      "reward : -135.80764117016972\n",
      "reward : -144.4936873530743\n",
      "reward : -152.94189797261487\n",
      "reward : -161.22557550761886\n",
      "reward : -169.42937528438213\n",
      "reward : -177.6479097716571\n",
      "reward : -185.98279640174613\n",
      "reward : -194.53791527446464\n",
      "reward : -203.4148890929468\n",
      "reward : -212.70724154210322\n",
      "reward : -222.49398287888027\n",
      "reward : -232.40745244415749\n",
      "reward : -241.8344669437668\n",
      "reward : -250.75522415021175\n",
      "reward : -259.1679767057459\n",
      "reward : -267.090261081276\n",
      "reward : -274.5591951000435\n",
      "reward : -281.63067112933106\n",
      "reward : -288.37747648265616\n",
      "reward : -294.8869016988811\n",
      "reward : -301.2579033057293\n",
      "reward : -307.5981881198832\n",
      "reward : -314.02163639326466\n",
      "reward : -320.6447167255921\n",
      "reward : -327.5830429634056\n",
      "reward : -334.9464536110535\n",
      "reward : -342.83561698233643\n",
      "reward : -351.337939445475\n",
      "reward : -360.5223357403675\n",
      "reward : -370.43304694851264\n",
      "reward : -380.56076560472724\n",
      "reward : -389.99345387768903\n",
      "reward : -398.7474211949991\n",
      "reward : -406.8632265560336\n",
      "reward : -414.40612091368644\n",
      "reward : -421.4652046716218\n",
      "reward : -428.1528242994735\n",
      "reward : -434.6028571866184\n",
      "reward : -440.96920430819927\n",
      "reward : -447.42548813202274\n",
      "reward : -454.16060879349016\n",
      "reward : -461.3697480467039\n",
      "reward : -469.24114557560125\n",
      "reward : -477.9387805843413\n",
      "reward : -487.59203469820716\n",
      "reward : -498.2847142336432\n",
      "reward : -508.1840278824237\n",
      "reward : -517.1969428852822\n",
      "reward : -525.3232913208539\n",
      "reward : -532.5989517922229\n",
      "reward : -539.0964515799333\n",
      "reward : -544.9229792750433\n",
      "reward : -550.2143005894029\n",
      "reward : -555.1265208855683\n",
      "reward : -559.828246506051\n",
      "reward : -564.4951662556501\n",
      "reward : -569.3079275757417\n",
      "reward : -574.4505869977343\n",
      "reward : -580.1081119112382\n",
      "reward : -586.4641162492657\n",
      "reward : -593.6954280899154\n",
      "reward : -601.9595109607886\n",
      "reward : -611.3788263894871\n",
      "reward : -622.0283304513962\n",
      "reward : -632.638732250778\n",
      "reward : -642.1475708119684\n",
      "reward : -650.5683069185657\n",
      "reward : -657.9551657684343\n",
      "reward : -664.4038407914214\n",
      "reward : -670.0477487564161\n",
      "reward : -675.0513378908137\n",
      "reward : -679.6027464817854\n",
      "reward : -683.909118294035\n",
      "reward : -688.1975380425652\n",
      "reward : -692.7213685805808\n",
      "reward : -697.7592878223115\n",
      "reward : -703.603174805851\n",
      "reward : -710.5351023981963\n",
      "reward : -718.8071832613917\n",
      "reward : -728.6150508825483\n",
      "reward : -740.0748207266167\n",
      "reward : -751.1606085758943\n",
      "reward : -760.9027102193079\n",
      "reward : -769.2843337464489\n",
      "reward : -776.3526547424971\n",
      "reward : -782.2202463558597\n",
      "reward : -787.0541010468172\n",
      "reward : -791.059190511562\n",
      "reward : -794.4602338713235\n",
      "reward : -797.4861264656334\n",
      "reward : -800.3601399268478\n",
      "reward : -803.2981715530908\n",
      "reward : -806.5143493590571\n",
      "reward : -810.2318615098084\n",
      "reward : -814.6907894829088\n",
      "reward : -820.1454023878392\n",
      "reward : -826.854591186239\n",
      "reward : -835.0575801519891\n",
      "reward : -844.9483008285205\n",
      "reward : -856.6449121528785\n",
      "reward : -868.4411411299117\n",
      "reward : -878.7089004554178\n",
      "reward : -887.445596214228\n",
      "reward : -894.7127490463007\n",
      "reward : -900.637157119358\n",
      "reward : -905.3986414488306\n",
      "reward : -909.2106233451325\n",
      "reward : -912.3010361754266\n",
      "reward : -914.8994666968379\n",
      "reward : -917.2334960819426\n",
      "reward : -919.5333760454574\n",
      "reward : -922.0486048761944\n",
      "reward : -925.0584615132068\n",
      "reward : -928.8800174721254\n",
      "reward : -933.8593754426402\n",
      "reward : -940.3573442818192\n",
      "reward : -948.7177233201547\n",
      "reward : -959.2195971908261\n",
      "reward : -972.0244526967823\n",
      "reward : -984.8557021584008\n",
      "reward : -995.8763696765077\n",
      "reward : -1005.0412055800673\n",
      "reward : -1012.4097093643188\n",
      "reward : -1018.1448113157644\n",
      "reward : -1022.4879393001759\n",
      "reward : -1025.7159005003955\n",
      "reward : -1028.1059053359152\n",
      "reward : -1029.9087828369825\n",
      "reward : -1031.3414884445963\n",
      "reward : -1032.5892915146485\n",
      "reward : -1033.8132092110136\n",
      "reward : -1035.1621802528525\n",
      "reward : -1036.7908591599994\n",
      "reward : -1038.8777718041542\n",
      "reward : -1041.6392320073037\n",
      "reward : -1045.3353874926565\n",
      "reward : -1050.269320170025\n",
      "reward : -1056.7786673853045\n",
      "reward : -1065.2008621192485\n",
      "reward : -1075.822867586529\n",
      "reward : -1088.8244611516197\n",
      "reward : -1102.3408048304732\n",
      "reward : -1113.9388672086843\n",
      "reward : -1123.5898340167575\n",
      "reward : -1131.3600237664946\n",
      "reward : -1137.4169353938448\n",
      "reward : -1142.0012163280298\n",
      "reward : -1145.383466029651\n",
      "reward : -1147.8277302019303\n",
      "reward : -1149.568712394467\n",
      "reward : -1150.8043644060683\n",
      "reward : -1151.6970409136436\n",
      "reward : -1152.3801521164332\n",
      "reward : -1152.9684420153997\n",
      "reward : -1153.5677303967448\n",
      "reward : -1154.2882091608644\n",
      "reward : -1155.2584833108072\n",
      "reward : -1156.6391456360034\n",
      "reward : -1158.6366425372264\n",
      "reward : -1161.5195673291312\n",
      "reward : -1165.6314144752098\n",
      "reward : -1171.3881153403809\n",
      "reward : -1179.2450580333812\n",
      "reward : -1189.6328142314012\n",
      "reward : -1202.8614285776812\n",
      "reward : -1218.7117967280356\n",
      "reward : -1232.3960451295188\n",
      "reward : -1243.7797024634178\n",
      "reward : -1252.868212535057\n",
      "reward : -1259.832537928208\n",
      "reward : -1264.9778676816954\n",
      "reward : -1268.6670269329397\n",
      "reward : -1271.2551638482332\n",
      "reward : -1273.0453638366052\n",
      "reward : -1274.2743391656156\n",
      "reward : -1275.1191565415018\n",
      "reward : -1275.7065688208659\n",
      "reward : -1276.1261624616927\n",
      "reward : -1276.4406362525228\n",
      "reward : -1276.6951291906773\n",
      "reward : -1276.9245750590214\n",
      "reward : -1277.159497854381\n",
      "reward : -1277.431192640091\n",
      "reward : -1277.7765962853287\n",
      "reward : -1278.243808120783\n"
     ]
    }
   ],
   "source": [
    "model.test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.4086331 ,  0.69766575,  4.6289186 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 12 11  3  9  7  4  8 14 10  1  2  6  0 13]\n",
      "[ 5 12 11]\n",
      "[[0.38666955 0.42141143 0.40985762 0.01468469]\n",
      " [0.40550966 0.60388158 0.95610237 0.1183427 ]\n",
      " [0.37009791 0.84542052 0.6843701  0.76762253]\n",
      " [0.46696066 0.9848017  0.85470799 0.03833604]\n",
      " [0.82915049 0.94522254 0.35927148 0.6564547 ]\n",
      " [0.78730688 0.14303128 0.09686446 0.13922546]\n",
      " [0.56542147 0.64102809 0.34124912 0.970972  ]\n",
      " [0.19045474 0.18122974 0.26487631 0.39102986]\n",
      " [0.78770073 0.46208566 0.41728664 0.30025914]\n",
      " [0.01678557 0.44009727 0.70587051 0.51571985]\n",
      " [0.40680957 0.04405536 0.91335008 0.14416954]\n",
      " [0.51247322 0.32248927 0.74582712 0.1620112 ]\n",
      " [0.88734814 0.2709744  0.50023687 0.22386461]\n",
      " [0.28860308 0.956961   0.85164722 0.58042007]\n",
      " [0.39329904 0.59037354 0.22291441 0.73320636]]\n",
      "[3 9 7]\n",
      "[[0.38666955 0.42141143 0.40985762 0.01468469]\n",
      " [0.40550966 0.60388158 0.95610237 0.1183427 ]\n",
      " [0.37009791 0.84542052 0.6843701  0.76762253]\n",
      " [0.46696066 0.9848017  0.85470799 0.03833604]\n",
      " [0.82915049 0.94522254 0.35927148 0.6564547 ]\n",
      " [0.78730688 0.14303128 0.09686446 0.13922546]\n",
      " [0.56542147 0.64102809 0.34124912 0.970972  ]\n",
      " [0.19045474 0.18122974 0.26487631 0.39102986]\n",
      " [0.78770073 0.46208566 0.41728664 0.30025914]\n",
      " [0.01678557 0.44009727 0.70587051 0.51571985]\n",
      " [0.40680957 0.04405536 0.91335008 0.14416954]\n",
      " [0.51247322 0.32248927 0.74582712 0.1620112 ]\n",
      " [0.88734814 0.2709744  0.50023687 0.22386461]\n",
      " [0.28860308 0.956961   0.85164722 0.58042007]\n",
      " [0.39329904 0.59037354 0.22291441 0.73320636]]\n",
      "[ 4  8 14]\n",
      "[[0.38666955 0.42141143 0.40985762 0.01468469]\n",
      " [0.40550966 0.60388158 0.95610237 0.1183427 ]\n",
      " [0.37009791 0.84542052 0.6843701  0.76762253]\n",
      " [0.46696066 0.9848017  0.85470799 0.03833604]\n",
      " [0.82915049 0.94522254 0.35927148 0.6564547 ]\n",
      " [0.78730688 0.14303128 0.09686446 0.13922546]\n",
      " [0.56542147 0.64102809 0.34124912 0.970972  ]\n",
      " [0.19045474 0.18122974 0.26487631 0.39102986]\n",
      " [0.78770073 0.46208566 0.41728664 0.30025914]\n",
      " [0.01678557 0.44009727 0.70587051 0.51571985]\n",
      " [0.40680957 0.04405536 0.91335008 0.14416954]\n",
      " [0.51247322 0.32248927 0.74582712 0.1620112 ]\n",
      " [0.88734814 0.2709744  0.50023687 0.22386461]\n",
      " [0.28860308 0.956961   0.85164722 0.58042007]\n",
      " [0.39329904 0.59037354 0.22291441 0.73320636]]\n",
      "[10  1  2]\n",
      "[[0.38666955 0.42141143 0.40985762 0.01468469]\n",
      " [0.40550966 0.60388158 0.95610237 0.1183427 ]\n",
      " [0.37009791 0.84542052 0.6843701  0.76762253]\n",
      " [0.46696066 0.9848017  0.85470799 0.03833604]\n",
      " [0.82915049 0.94522254 0.35927148 0.6564547 ]\n",
      " [0.78730688 0.14303128 0.09686446 0.13922546]\n",
      " [0.56542147 0.64102809 0.34124912 0.970972  ]\n",
      " [0.19045474 0.18122974 0.26487631 0.39102986]\n",
      " [0.78770073 0.46208566 0.41728664 0.30025914]\n",
      " [0.01678557 0.44009727 0.70587051 0.51571985]\n",
      " [0.40680957 0.04405536 0.91335008 0.14416954]\n",
      " [0.51247322 0.32248927 0.74582712 0.1620112 ]\n",
      " [0.88734814 0.2709744  0.50023687 0.22386461]\n",
      " [0.28860308 0.956961   0.85164722 0.58042007]\n",
      " [0.39329904 0.59037354 0.22291441 0.73320636]]\n",
      "[ 6  0 13]\n",
      "[[0.38666955 0.42141143 0.40985762 0.01468469]\n",
      " [0.40550966 0.60388158 0.95610237 0.1183427 ]\n",
      " [0.37009791 0.84542052 0.6843701  0.76762253]\n",
      " [0.46696066 0.9848017  0.85470799 0.03833604]\n",
      " [0.82915049 0.94522254 0.35927148 0.6564547 ]\n",
      " [0.78730688 0.14303128 0.09686446 0.13922546]\n",
      " [0.56542147 0.64102809 0.34124912 0.970972  ]\n",
      " [0.19045474 0.18122974 0.26487631 0.39102986]\n",
      " [0.78770073 0.46208566 0.41728664 0.30025914]\n",
      " [0.01678557 0.44009727 0.70587051 0.51571985]\n",
      " [0.40680957 0.04405536 0.91335008 0.14416954]\n",
      " [0.51247322 0.32248927 0.74582712 0.1620112 ]\n",
      " [0.88734814 0.2709744  0.50023687 0.22386461]\n",
      " [0.28860308 0.956961   0.85164722 0.58042007]\n",
      " [0.39329904 0.59037354 0.22291441 0.73320636]]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(15)\n",
    "np.random.shuffle(a)\n",
    "print(a)\n",
    "\n",
    "for i in range(0,15,3):\n",
    "    end=i+3\n",
    "    s=a[i:end]\n",
    "    print(s)\n",
    "    obs[s]\n",
    "    print(obs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.random.random((15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56542147, 0.64102809, 0.34124912, 0.970972  ],\n",
       "       [0.40550966, 0.60388158, 0.95610237, 0.1183427 ],\n",
       "       [0.01678557, 0.44009727, 0.70587051, 0.51571985]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[ [6 , 1 , 9  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56542147, 0.64102809, 0.34124912, 0.970972  ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reshaped b_obs shape: (48, 4)\n",
      "Reshaped b_obs array:\n",
      "[[0.69481385 0.55587527 0.59367642 0.43085629]\n",
      " [0.06018066 0.55972636 0.50987688 0.7082999 ]\n",
      " [0.6687081  0.01696573 0.95235547 0.71893289]\n",
      " [0.86241116 0.94448639 0.1919117  0.79956276]\n",
      " [0.15974269 0.47357438 0.91224694 0.84041706]\n",
      " [0.82476058 0.45363581 0.64457352 0.99012367]\n",
      " [0.06977143 0.38832778 0.45637532 0.31244277]\n",
      " [0.01991948 0.46190861 0.87037294 0.40705147]\n",
      " [0.53147438 0.77282349 0.70829398 0.39447202]\n",
      " [0.88396667 0.68114601 0.870091   0.5473923 ]\n",
      " [0.50992395 0.3644409  0.46914774 0.15111726]\n",
      " [0.20977973 0.36086775 0.87545821 0.32520184]\n",
      " [0.40439464 0.39570552 0.3175138  0.26564573]\n",
      " [0.74911804 0.73182795 0.07421998 0.38556994]\n",
      " [0.68844174 0.88303675 0.4857736  0.97369597]\n",
      " [0.86202223 0.90198655 0.20295541 0.65402601]\n",
      " [0.79461161 0.06150136 0.01174739 0.19729028]\n",
      " [0.22011213 0.81956466 0.25189302 0.49308405]\n",
      " [0.94009976 0.52974383 0.91776646 0.9444369 ]\n",
      " [0.20540657 0.19019668 0.25355413 0.74045101]\n",
      " [0.61704688 0.85186767 0.5549829  0.55331948]\n",
      " [0.4421984  0.18890133 0.608476   0.929715  ]\n",
      " [0.82693108 0.55012037 0.17931271 0.92138302]\n",
      " [0.83147593 0.53656101 0.64288329 0.6593345 ]\n",
      " [0.04839579 0.47549673 0.09975464 0.69323728]\n",
      " [0.58620562 0.10125728 0.94771365 0.88400317]\n",
      " [0.29952197 0.37514223 0.73456923 0.07005297]\n",
      " [0.54834132 0.90212763 0.43858861 0.37437028]\n",
      " [0.61753576 0.91456393 0.70776049 0.99034931]\n",
      " [0.3720206  0.23076987 0.65336597 0.06306299]\n",
      " [0.41102759 0.73341615 0.45164    0.77259306]\n",
      " [0.62155306 0.61438576 0.77527836 0.31185795]\n",
      " [0.83686439 0.26653912 0.04364216 0.13168036]\n",
      " [0.01315837 0.1069187  0.74078926 0.21085589]\n",
      " [0.59960703 0.4206853  0.56374045 0.79624567]\n",
      " [0.38319322 0.58666035 0.80262177 0.66505447]\n",
      " [0.40812099 0.65304006 0.31179404 0.43443119]\n",
      " [0.67391219 0.67318803 0.57635056 0.45412217]\n",
      " [0.81625674 0.66575483 0.01152207 0.3974277 ]\n",
      " [0.30815144 0.58040352 0.3590607  0.35516113]\n",
      " [0.85264045 0.2907368  0.92165786 0.40822642]\n",
      " [0.28311859 0.10112234 0.79044603 0.41092006]\n",
      " [0.04956652 0.41561685 0.97114642 0.52825878]\n",
      " [0.93435049 0.38501703 0.30669056 0.45547499]\n",
      " [0.40618516 0.28295394 0.00631811 0.94011621]\n",
      " [0.51338502 0.28513172 0.77206049 0.73059962]\n",
      " [0.50894439 0.97467819 0.44321598 0.45480617]\n",
      " [0.68260891 0.19344037 0.79327961 0.45956089]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppose the environment has a single observation space shape of (2, 2)\n",
    "single_observation_space_shape = (3,)\n",
    "\n",
    "# Generate a random observation array with shape (4, 2, 2)\n",
    "obs = np.random.random((12,4,4))\n",
    "\n",
    "# Reshape the obs array to match the single_observation_space shape\n",
    "b_obs = obs.reshape((-1,) +(4,))\n",
    "\n",
    "# Print the original and reshaped arrays\n",
    "\n",
    "print(\"\\nReshaped b_obs shape:\", b_obs.shape)\n",
    "print(\"Reshaped b_obs array:\")\n",
    "print(b_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env=gym.make('CartPole-v1')\n",
    "env = gym.wrappers.RecordEpisodeStatistics(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raeda\\AppData\\Roaming\\Python\\Python311\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.01414056,  0.20427078, -0.00602352, -0.33814648], dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state,_=env1.reset()\n",
    "\n",
    "a=torch.tensor(state, dtype=torch.float)\n",
    "# a=a.flatten()\n",
    "A=torch.diag(a)\n",
    "\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0430,  0.4156, -0.0049, -0.5542], device='cuda:0')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.tensor(env.step(1)[0], dtype=torch.float).to(device)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'timesteps_per_batch': 2048, \n",
    "\t\t\t\t'max_timesteps_per_episode': 200, \n",
    "\t\t\t\t'gamma': 0.99, \n",
    "\t\t\t\t'n_updates_per_iteration': 10,\n",
    "\t\t\t\t'lr': 3e-4, \n",
    "\t\t\t\t'clip': 0.2,\n",
    "\t\t\t\t'render': True,\n",
    "\t\t\t\t'render_every_i': 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7888304], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1=gym.make('Pendulum-v1')\n",
    "env1.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.91116554, -0.41204044,  0.3663817 ], dtype=float32),\n",
       " -7.548833920978005,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=env1.reset()\n",
    "env1.step(env1.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
